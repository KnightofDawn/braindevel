{
    templates: {
        raw_net_no_drop_time_layers: [ 
            &l_in !obj:lasagne.layers.InputLayer {                 
                shape: [null, in_sensors, $input_time_length, in_cols]
        },

        &conv1  !obj:lasagne.layers.Conv2DLayer { 
            incoming: *l_in, 
            num_filters: 256, 
            filter_size: [9, 1],
            stride: 1, pad: 'same',
            W: !obj:lasagne.init.Normal { 
                std: 1e-2},
            nonlinearity: null},
        &bn1 !obj:braindecode.veganlasagne.batch_norm.BatchNormLayer { 
            incoming: *conv1, epsilon: 0.0000000001,
             nonlinearity: !!python/name:lasagne.nonlinearities.very_leaky_rectify
         },

        pool1: Pool2DLayer { 
        incoming: bn1, pool_size:  { 4, 1}, stride:  { 1, 1}}
    reshape1: StrideReshapeLayer { pool1, n_stride:4}
    pool1: lasagne.layers.SliceLayer { reshape1, indices:slice { 0,32}, axis:0}
    drop1: lasagne.layers.DropoutLayer { incoming: pool1, p: p1}

    conv2: Conv2DLayer { incoming: drop1, num_filters: 256, filter_size:  { 1, 1},
                        stride: 1, pad: 'same',
                        W: lasagne.init.Normal { std: std},
                        nonlinearity: None}

    bn2: BatchNormLayer { incoming: conv2, epsilon: 0.0000000001,
                         nonlinearity: lasagne.nonlinearities.very_leaky_rectify}

    conv2a: Conv2DLayer { incoming: bn2, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: lasagne.init.Normal { std: std}, b: None,
                         nonlinearity: None}

    sum2a: SumLayer { incomings: [conv2, conv2a], coeffs: 1}
    
    bn2a: BatchNormLayer { incoming: sum2a, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv2b: Conv2DLayer { incoming: bn2a, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv2a.W, b: None,
                         nonlinearity: None}

    sum2b: SumLayer { incomings: [conv2, conv2b], coeffs: 1}
    
    bn2b: BatchNormLayer { incoming: sum2b, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv2c: Conv2DLayer { incoming: bn2b, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv2a.W, b: None,
                         nonlinearity: None}

    sum2c: SumLayer { incomings: [conv2, conv2c], coeffs: 1}
    
    bn2c: BatchNormLayer { incoming: sum2c, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    pool2: Pool2DLayer { incoming: bn2c, pool_size:  { 4, 1}, stride:  { 1, 1}}
    pool2: StrideReshapeLayer { pool2, n_stride:4}
    pool2: lasagne.layers.SliceLayer { pool2, indices:slice { 0,32}, axis:0}

    drop2: lasagne.layers.DropoutLayer { incoming: pool2, p: p2}

    conv3: Conv2DLayer { incoming: drop2, num_filters: 256, filter_size:  { 1, 1},
                        stride: 1, pad: 'same',
                        W: lasagne.init.Normal { std: std},
                        nonlinearity: None}

    bn3: BatchNormLayer { incoming: conv3, epsilon: 0.0000000001,
                         nonlinearity: lasagne.nonlinearities.very_leaky_rectify}

    conv3a: Conv2DLayer { incoming: bn3, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: lasagne.init.Normal { std: std}, b: None,
                         nonlinearity: None}

    sum3a: SumLayer { incomings: [conv3, conv3a], coeffs: 1}
    
    bn3a: BatchNormLayer { incoming: sum3a, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv3b: Conv2DLayer { incoming: bn3a, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv3a.W, b: None,
                         nonlinearity: None}

    sum3b: SumLayer { incomings: [conv3, conv3b], coeffs: 1}
    
    bn3b: BatchNormLayer { incoming: sum3b, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv3c: Conv2DLayer { incoming: bn3b, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv3a.W, b: None,
                         nonlinearity: None}

    sum3c: SumLayer { incomings: [conv3, conv3c], coeffs: 1}
    
    bn3c: BatchNormLayer { incoming: sum3c, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    pool3: Pool2DLayer { incoming: bn3c, pool_size:  { 4, 1}, stride:  { 1, 1}}
    pool3: StrideReshapeLayer { pool3, n_stride:4}
    pool3: lasagne.layers.SliceLayer { pool3, indices:slice { 0,32}, axis:0}

    drop3: lasagne.layers.DropoutLayer { incoming: pool3, p: p3}

    conv4: Conv2DLayer { incoming: drop3, num_filters: 256, filter_size:  { 1, 1},
                        stride: 1, pad: 'same',
                        W: lasagne.init.Normal { std: std},
                        nonlinearity: None}

    bn4: BatchNormLayer { incoming: conv4, epsilon: 0.0000000001,
                         nonlinearity: lasagne.nonlinearities.very_leaky_rectify}

    conv4a: Conv2DLayer { incoming: bn4, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: lasagne.init.Normal { std: std}, b: None,
                         nonlinearity: None}

    sum4a: SumLayer { incomings: [conv4, conv4a], coeffs: 1}
    
    bn4a: BatchNormLayer { incoming: sum4a, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv4b: Conv2DLayer { incoming: bn4a, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv4a.W, b: None,
                         nonlinearity: None}

    sum4b: SumLayer { incomings: [conv4, conv4b], coeffs: 1}
    
    bn4b: BatchNormLayer { incoming: sum4b, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv4c: Conv2DLayer { incoming: bn4b, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv4a.W, b: None,
                         nonlinearity: None}

    sum4c: SumLayer { incomings: [conv4, conv4c], coeffs: 1}
    
    bn4c: BatchNormLayer { incoming: sum4c, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    pool4: Pool2DLayer { incoming: bn4c, pool_size:  { 4, 1}, stride:  { 1, 1}}
    pool4: StrideReshapeLayer { pool4, n_stride:4}
    pool4: lasagne.layers.SliceLayer { pool4, indices:slice { 0,32}, axis:0}

    drop4: lasagne.layers.DropoutLayer { incoming: pool4, p: p4}

    conv5: Conv2DLayer { incoming: drop4, num_filters: 256, filter_size:  { 1, 1},
                        stride: 1, pad: 'same',
                        W: lasagne.init.Normal { std: std},
                        nonlinearity: None}

    bn5: BatchNormLayer { incoming: conv5, epsilon: 0.0000000001,
                         nonlinearity: lasagne.nonlinearities.very_leaky_rectify}

    conv5a: Conv2DLayer { incoming: bn5, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: lasagne.init.Normal { std: std}, b: None,
                         nonlinearity: None}

    sum5a: SumLayer { incomings: [conv5, conv5a], coeffs: 1}
    
    bn5a: BatchNormLayer { incoming: sum5a, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv5b: Conv2DLayer { incoming: bn5a, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv5a.W, b: None,
                         nonlinearity: None}

    sum5b: SumLayer { incomings: [conv5, conv5b], coeffs: 1}
    
    bn5b: BatchNormLayer { incoming: sum5b, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    conv5c: Conv2DLayer { incoming: bn5b, num_filters: 256, filter_size:  { 9, 1},
                         stride: 1, pad: 'same',
                         W: conv5a.W, b: None,
                         nonlinearity: None}

    sum5c: SumLayer { incomings: [conv5, conv5c], coeffs: 1}
    
    bn5c: BatchNormLayer { incoming: sum5c, epsilon: 0.0000000001,
                          nonlinearity: lasagne.nonlinearities.rectify}    

    pool5: Pool2DLayer { incoming: bn5c, pool_size:  { 2, 1}, stride:  { 1, 1}}
    pool5: StrideReshapeLayer { pool5, n_stride:2}
    pool5: lasagne.layers.SliceLayer { pool5, indices:slice { 0,32}, axis:0}

    l_out: Conv2DLayer { incoming: pool5, num_filters: num_events,
                                filter_size:  { 7, 1},
                                 W: lasagne.init.Normal { std: std},
                                 nonlinearity: lasagne.nonlinearities.identity}
    l_out: FinalReshapeLayer { incoming: l_out}
    l_out: lasagne.layers.NonlinearityLayer { l_out, nonlinearity:lasagne.nonlinearities.sigmoid}
        ],
        raw_layer_names_to_norms: {
            time_conv: $conv_norm,
            spat_conv: $conv_norm,
            combined_conv_2: $conv_norm,
            combined_conv_3: $conv_norm,
            combined_conv_4: $conv_norm,
            combined_conv_5: $conv_norm,
            final_dense: $final_norm,
        },
        square: !!python/name:theano.tensor.sqr ,
        identity: !!python/name:lasagne.nonlinearities.identity ,
        relu: !!python/name:lasagne.nonlinearities.rectify ,
        leaky_relu: !!python/name:lasagne.nonlinearities.leaky_rectify ,
        safe_log: !!python/name:braindecode.veganlasagne.nonlinearities.safe_log ,
    },
    variants: [[{
        layer_names_to_norms: [$raw_layer_names_to_norms],
        layers: [$raw_net_no_drop_time_layers],
        final_norm: [0.5],
        conv_norm: [2.0],
    }]]
}
