{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCI Competition 4 Dataset 2a Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I show the evolution of the 5-layer performance across changing:\n",
    "* number of filters\n",
    "* filter lengths\n",
    "* avg pooling in final layer instead of fully connected\n",
    "* dropout on input\n",
    "* tied losses for samples of same trial\n",
    "* squared activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original values for the samplewise trained model were:\n",
    "\n",
    "|Highpass|Test|\n",
    "|-|\n",
    "|-|**65.6%**|\n",
    "|4|**61.7%**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Doubling after pooling increases ~3% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, we had 40 units per layer, we tried:\n",
    "  * 20,40,80,160\n",
    "  * 25,50,100,200\n",
    "  * 32,48,72,108\n",
    "  * 32,64,128,256\n",
    "  \n",
    "\n",
    "|#Units|Highpass|Test|\n",
    "|-|\n",
    "|20,40,80,160|-|68.1%|\n",
    "|20,40,80,160|4|63.1%|\n",
    "|25,50,100,200|-|**69.5%**|\n",
    "|25,50,100,200|4|**64.0%**|\n",
    "|32,48,72,108|-|63.9%|\n",
    "|32,48,72,108|-|63.8%|\n",
    "|32,64,128,256|-|68.6%|\n",
    "|32,64,128,256|-|65.9%|\n",
    "\n",
    "I continued with 25,50,100,200 since its faster and close to 32,64,128,256. Also I made a mistake (evaluating an experiment which had not finished on all datasets) which led me to believe the 32,64,128,256 is less robust... neverthless at the end of this notebook, I recompare the final model to 32,64,128,256 and there are no big improvements with 32,64,128,256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 15,7,3,3 is >5% worse than 10,10,10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made some smaller experiments with different filter lengths (15,7,3,3 compared to 10,10,10,10) in later layers which all had significantly worse results (< 60%). Might have to try more variants for a fairer comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AvgPool + Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average pool helps a little on highpassed data\n",
    "* same for dropout\n",
    "\n",
    "Using 25,50,100,200, we got:\n",
    "\n",
    "|Highpass|Dropout in|Test|\n",
    "|-|\n",
    "|-|-|67.6%|\n",
    "|4|-|65.1%|\n",
    "|-|0.1|**67.5%**|\n",
    "|4|0.1|**66.4%**|\n",
    "|-|0.3|68.1%|\n",
    "|4|0.3|66.0%|\n",
    "\n",
    "I resumed with dropout 0.1 (**in bold**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* modest increase without highpass, very modest decrease with highpass -> inconclusive, not pursued further\n",
    "\n",
    "Did not help much. Note that factorization of for example 11x1 into 6x1+6x1 increases the number of weights (in contrast with 2d-filters where 11x11 has more parameters than 6x6+6x6).\n",
    "\n",
    "|Highpass|nonlin between|Test|\n",
    "|-|\n",
    "|-|-|70.7%|\n",
    "|4|-|65.9%|\n",
    "|-|elu|68.0%|\n",
    "|4|elu|63.3%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tied Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tying neighbouring losses increases ~1%\n",
    "\n",
    "I tested either using 1,10 or 100 randomly chosen pairs (chosen so that any sample maximally appears once) or using all neighbouring samples.\n",
    "\n",
    "\n",
    "|Highpass|Tied pairs|Drop in prob|Test|\n",
    "|-|\n",
    "|-|1|0.0|65.8%|\n",
    "|-|10|0.0|68.0%|\n",
    "|-|100|0.0|67.8%|\n",
    "|-|neighb|0.0|**69.7%**|\n",
    "|4|1|0.0|62.5%|\n",
    "|4|10|0.0|66.7%|\n",
    "|4|100|0.0|67.4%|\n",
    "|4|neighb|0.0|**67.7%**|\n",
    "|-|1|0.1|64.2%|\n",
    "|-|10|0.1|66.8%|\n",
    "|-|100|0.1|67.2%|\n",
    "|-|neighb|0.1|70.2%|\n",
    "|4|1|0.1|60.7%|\n",
    "|4|10|0.1|64.3%|\n",
    "|4|100|0.1|65.7%|\n",
    "|4|neighb|0.1|65.7%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing avg pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing avg pool very modst decrease for highpass, modest increase for no highpass -> used due to more conceptual simplicity of the model (no special avg pooling layer at end)\n",
    "\n",
    "|Highpass|Tied pairs|Drop in prob|Test|\n",
    "|-|\n",
    "|-|neighb|0.0|**71.0%**|\n",
    "|4|neighb|0.0|**67.2%**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data comparison\n",
    "\n",
    "* Removing avg makes bug problems >3% worsening on our data without highpass, therefore retried our data with resampling\n",
    "\n",
    "unfortunately removing avg is a big problem here for one  :(\n",
    "\n",
    "|Highpass|Tied pairs|#units|avg|Test|\n",
    "|-|\n",
    "|-|no|40,40,40,40|no|90.6%|\n",
    "|4|no|40,40,40,40|no|86.7%|\n",
    "|-|neighb|25,50,100,200|yes|89.9%|\n",
    "|4|neighb|25,50,100,200|yes|89.0%|\n",
    "|-|neighb|25,50,100,200|no|86.8%|\n",
    "|4|neighb|25,50,100,200|no|89.2%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data 250 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Resampling leads to same results as before with avgpool -> final model for both bci competition and our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Highpass|1st Filter Length|Tied pairs|#units|avg|Test|\n",
    "|-|\n",
    "|-|neighb|10|25,50,100,200|no|**89.3%/89.4%**|\n",
    "|4|neighb|10|25,50,100,200|no|**88.9%/89.2%**|\n",
    "|-|neighb|10|32,64,128,256|no|90.3%|\n",
    "|4|neighb|10|32,64,128,256|no|88.1%|\n",
    "|-|neighb|25|25,50,100,200|no|89.6%|\n",
    "|4|neighb|25|25,50,100,200|no|86.9%|\n",
    "|-|neighb|25|32,64,128,256|no|90.4%|\n",
    "|4|neighb|25|32,64,128,256|no|86.9%|\n",
    "\n",
    "The two values for the final configuration are from two different, supposedly identical runs. So difference is either due to CuDNNs' inherent indeterminism or some bug of mine.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square auf 250 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring is not helpful in any way, if only on first layer atleast performance is similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Highpass|Tied pairs|#units|avg|square layers|Test|\n",
    "|-|\n",
    "|-|neighb|25,50,100,200|no|first|86.5%|\n",
    "|4|neighb|25,50,100,200|no|first|88.7%|\n",
    "|-|neighb|25,50,100,200|no|all|84.3%|\n",
    "|4|neighb|25,50,100,200|no|all|83.1%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the final model choice is:\n",
    "* 25,50,100,200 filters\n",
    "* all filter lengths 10\n",
    "* no dropout on input\n",
    "* tied neighbour losses\n",
    "* no squaring\n",
    "* no avg pooling\n",
    "* resampling our data to 250 Hz\n",
    "\n",
    "\n",
    "### Our Data\n",
    "\n",
    "|Highpass|Test|\n",
    "|-|\n",
    "|-|**89.3%/89.4%**|\n",
    "|4|**88.9%/89.2%**|\n",
    "\n",
    "\n",
    "### BCI Competition Data\n",
    "\n",
    "|Highpass|Test|\n",
    "|-|\n",
    "|-|**71.0%**|\n",
    "|4|**67.2%**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
