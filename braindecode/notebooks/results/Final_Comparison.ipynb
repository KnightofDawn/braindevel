{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "site.addsitedir('/home/schirrmr/.local/lib/python2.7/site-packages/')\n",
    "site.addsitedir('/usr/lib/pymodules/python2.7/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "%cd /home/schirrmr/braindecode/code/braindecode/\n",
    "assert 'THEANO_FLAGS' in os.environ\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' \n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from braindecode.scripts.print_results import ResultPrinter\n",
    "from braindecode.csp.print_results import CSPResultPrinter\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel(\"DEBUG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.analysis.pandas_util import load_data_frame, remove_columns_with_same_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.analysis.pandas_util import pairwise_compare_frame, dataset_averaged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(time, len), (time, tmean), (time, tstd), (test, mean), (test, std), (train, mean), (train, std)]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_cnt_ours = load_data_frame('data/models/paper/ours/cnt//merged//', shorten_headers=False).drop(\n",
    "    ['num_filters_4', 'num_filters_spat'], axis=1)\n",
    "\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_merged_cnt_ours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_exp</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>diff</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low_cut_hz</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>89.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_abs_threshold</th>\n",
       "      <td>40</td>\n",
       "      <td>800</td>\n",
       "      <td>400</td>\n",
       "      <td>90.5</td>\n",
       "      <td>89.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonlin_before_merge</th>\n",
       "      <td>40</td>\n",
       "      <td>elu_identity</td>\n",
       "      <td>elu</td>\n",
       "      <td>90.2</td>\n",
       "      <td>89.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_filters_2</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>89.9</td>\n",
       "      <td>89.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_exp         val_1 val_2  acc_1  acc_2  diff  std\n",
       "low_cut_hz              80             0     4   90.6   89.7  -0.9  4.3\n",
       "max_abs_threshold       40           800   400   90.5   89.9  -0.5  2.1\n",
       "nonlin_before_merge     40  elu_identity   elu   90.2   89.9  -0.3  2.5\n",
       "num_filters_2           40            50    48   89.9   89.9  -0.0  2.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_compare_frame(remove_columns_with_same_value(\n",
    "    df_merged_cnt_ours.drop(['s_n_filters_time', 'num_filters_time',\n",
    "                         'num_filters_3'], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_filters_time</th>\n",
       "      <th>s_n_filters_time</th>\n",
       "      <th>nonlin_before_merge</th>\n",
       "      <th>low_cut_hz</th>\n",
       "      <th>max_abs_threshold</th>\n",
       "      <th>layer_names_to_norms</th>\n",
       "      <th>num_filters_2</th>\n",
       "      <th>num_filters_3</th>\n",
       "      <th>time</th>\n",
       "      <th>test</th>\n",
       "      <th>test_sample</th>\n",
       "      <th>train</th>\n",
       "      <th>train_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu_identity</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>00:54:40</td>\n",
       "      <td>62.500</td>\n",
       "      <td>62.246868</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>00:57:36</td>\n",
       "      <td>62.500</td>\n",
       "      <td>61.867824</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu_identity</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>01:20:13</td>\n",
       "      <td>61.875</td>\n",
       "      <td>60.598252</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>01:04:52</td>\n",
       "      <td>61.875</td>\n",
       "      <td>61.407229</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>01:04:42</td>\n",
       "      <td>62.500</td>\n",
       "      <td>62.006133</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>01:03:30</td>\n",
       "      <td>61.875</td>\n",
       "      <td>60.923147</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>00:58:36</td>\n",
       "      <td>62.500</td>\n",
       "      <td>61.567719</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.993713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>01:44:23</td>\n",
       "      <td>61.875</td>\n",
       "      <td>61.159969</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_filters_time  s_n_filters_time nonlin_before_merge  low_cut_hz  \\\n",
       "17                 25                40        elu_identity           0   \n",
       "18                 25                40                 elu           0   \n",
       "19                 25                40        elu_identity           4   \n",
       "20                 25                40                 elu           4   \n",
       "90                 24                30                 elu           0   \n",
       "91                 24                30                 elu           4   \n",
       "127                25                40                 elu           0   \n",
       "131                25                40                 elu           4   \n",
       "\n",
       "     max_abs_threshold  layer_names_to_norms  num_filters_2  num_filters_3  \\\n",
       "17                 400                   NaN             50            100   \n",
       "18                 400                   NaN             50            100   \n",
       "19                 400                   NaN             50            100   \n",
       "20                 400                   NaN             50            100   \n",
       "90                 400                   NaN             48             72   \n",
       "91                 400                   NaN             48             72   \n",
       "127                800                   NaN             50            100   \n",
       "131                800                   NaN             50            100   \n",
       "\n",
       "        time    test  test_sample  train  train_sample  \n",
       "17  00:54:40  62.500    62.246868  100.0    100.000000  \n",
       "18  00:57:36  62.500    61.867824  100.0    100.000000  \n",
       "19  01:20:13  61.875    60.598252  100.0    100.000000  \n",
       "20  01:04:52  61.875    61.407229  100.0    100.000000  \n",
       "90  01:04:42  62.500    62.006133  100.0    100.000000  \n",
       "91  01:03:30  61.875    60.923147  100.0    100.000000  \n",
       "127 00:58:36  62.500    61.567719  100.0     99.993713  \n",
       "131 01:44:23  61.875    61.159969  100.0    100.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns_with_same_value(df_merged_cnt_ours[df_merged_cnt_ours.dataset_filename.str.contains('GuJo')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_norm_before_merge</th>\n",
       "      <th>nonlin_before_merge</th>\n",
       "      <th>low_cut_hz</th>\n",
       "      <th>max_abs_threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">identity</th>\n",
       "      <th>0</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:16:35</td>\n",
       "      <td>00:02:44</td>\n",
       "      <td>72.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:16:51</td>\n",
       "      <td>00:04:58</td>\n",
       "      <td>66.9</td>\n",
       "      <td>21.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">elu</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:16:11</td>\n",
       "      <td>00:04:02</td>\n",
       "      <td>73.2</td>\n",
       "      <td>15.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>9</td>\n",
       "      <td>00:29:26</td>\n",
       "      <td>00:06:04</td>\n",
       "      <td>71.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:17:56</td>\n",
       "      <td>00:08:02</td>\n",
       "      <td>67.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>98.9</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>9</td>\n",
       "      <td>00:28:35</td>\n",
       "      <td>00:11:48</td>\n",
       "      <td>66.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         time  \\\n",
       "                                                                          len   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold        \n",
       "False                   identity            0          400                  9   \n",
       "                                            4          400                  9   \n",
       "True                    elu                 0          400                  9   \n",
       "                                                       800                  9   \n",
       "                                            4          400                  9   \n",
       "                                                       800                  9   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                            tmean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:16:35   \n",
       "                                            4          400               00:16:51   \n",
       "True                    elu                 0          400               00:16:11   \n",
       "                                                       800               00:29:26   \n",
       "                                            4          400               00:17:56   \n",
       "                                                       800               00:28:35   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                             tstd   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:02:44   \n",
       "                                            4          400               00:04:58   \n",
       "True                    elu                 0          400               00:04:02   \n",
       "                                                       800               00:06:04   \n",
       "                                            4          400               00:08:02   \n",
       "                                                       800               00:11:48   \n",
       "\n",
       "                                                                          test  \\\n",
       "                                                                          mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                72.4   \n",
       "                                            4          400                66.9   \n",
       "True                    elu                 0          400                73.2   \n",
       "                                                       800                71.6   \n",
       "                                            4          400                67.5   \n",
       "                                                       800                66.2   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           std   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                16.1   \n",
       "                                            4          400                21.3   \n",
       "True                    elu                 0          400                15.5   \n",
       "                                                       800                17.7   \n",
       "                                            4          400                17.9   \n",
       "                                                       800                19.0   \n",
       "\n",
       "                                                                          train  \\\n",
       "                                                                           mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold          \n",
       "False                   identity            0          400                100.0   \n",
       "                                            4          400                100.0   \n",
       "True                    elu                 0          400                100.0   \n",
       "                                                       800                 99.9   \n",
       "                                            4          400                 98.9   \n",
       "                                                       800                 98.5   \n",
       "\n",
       "                                                                               \n",
       "                                                                          std  \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold       \n",
       "False                   identity            0          400                0.0  \n",
       "                                            4          400                0.0  \n",
       "True                    elu                 0          400                0.0  \n",
       "                                                       800                0.2  \n",
       "                                            4          400                3.4  \n",
       "                                                       800                4.6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_cnt_bcic = load_data_frame('data/models/paper/bci-competition/cnt//merged//', shorten_headers=False)\n",
    "\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_merged_cnt_bcic).drop('layer_names_to_norms', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.load import load_exp_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from braindecode.veganlasagne.layer_util import print_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_norm_before_merge</th>\n",
       "      <th>nonlin_before_merge</th>\n",
       "      <th>low_cut_hz</th>\n",
       "      <th>max_abs_threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">identity</th>\n",
       "      <th>0</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:06:15</td>\n",
       "      <td>00:01:55</td>\n",
       "      <td>62.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:06:12</td>\n",
       "      <td>00:01:11</td>\n",
       "      <td>55.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">elu</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:07:18</td>\n",
       "      <td>00:03:24</td>\n",
       "      <td>64.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>9</td>\n",
       "      <td>00:09:10</td>\n",
       "      <td>00:03:46</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>00:05:15</td>\n",
       "      <td>00:01:14</td>\n",
       "      <td>48.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>92.8</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>9</td>\n",
       "      <td>00:06:50</td>\n",
       "      <td>00:01:44</td>\n",
       "      <td>48.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>90.2</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         time  \\\n",
       "                                                                          len   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold        \n",
       "False                   identity            0          400                  9   \n",
       "                                            4          400                  9   \n",
       "True                    elu                 0          400                  9   \n",
       "                                                       800                  9   \n",
       "                                            4          400                  9   \n",
       "                                                       800                  9   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                            tmean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:06:15   \n",
       "                                            4          400               00:06:12   \n",
       "True                    elu                 0          400               00:07:18   \n",
       "                                                       800               00:09:10   \n",
       "                                            4          400               00:05:15   \n",
       "                                                       800               00:06:50   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                             tstd   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:01:55   \n",
       "                                            4          400               00:01:11   \n",
       "True                    elu                 0          400               00:03:24   \n",
       "                                                       800               00:03:46   \n",
       "                                            4          400               00:01:14   \n",
       "                                                       800               00:01:44   \n",
       "\n",
       "                                                                          test  \\\n",
       "                                                                          mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                62.9   \n",
       "                                            4          400                55.7   \n",
       "True                    elu                 0          400                64.9   \n",
       "                                                       800                66.0   \n",
       "                                            4          400                48.5   \n",
       "                                                       800                48.7   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           std   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                10.9   \n",
       "                                            4          400                15.3   \n",
       "True                    elu                 0          400                13.0   \n",
       "                                                       800                14.5   \n",
       "                                            4          400                 9.0   \n",
       "                                                       800                 7.5   \n",
       "\n",
       "                                                                          train  \\\n",
       "                                                                           mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold          \n",
       "False                   identity            0          400                100.0   \n",
       "                                            4          400                 99.9   \n",
       "True                    elu                 0          400                 99.9   \n",
       "                                                       800                100.0   \n",
       "                                            4          400                 92.8   \n",
       "                                                       800                 90.2   \n",
       "\n",
       "                                                                                \n",
       "                                                                           std  \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold        \n",
       "False                   identity            0          400                 0.0  \n",
       "                                            4          400                 0.2  \n",
       "True                    elu                 0          400                 0.2  \n",
       "                                                       800                 0.0  \n",
       "                                            4          400                 8.6  \n",
       "                                                       800                10.5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_bcic = load_data_frame('data/models/paper/bci-competition/epo/merged//', shorten_headers=False)\n",
    "\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_merged_bcic.drop('layer_names_to_norms', axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_norm_before_merge</th>\n",
       "      <th>nonlin_before_merge</th>\n",
       "      <th>low_cut_hz</th>\n",
       "      <th>max_abs_threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">identity</th>\n",
       "      <th>0</th>\n",
       "      <th>400</th>\n",
       "      <td>20</td>\n",
       "      <td>00:25:21</td>\n",
       "      <td>00:07:25</td>\n",
       "      <td>88.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>400</th>\n",
       "      <td>20</td>\n",
       "      <td>00:28:06</td>\n",
       "      <td>00:08:41</td>\n",
       "      <td>82.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">elu</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>400</th>\n",
       "      <td>20</td>\n",
       "      <td>00:27:36</td>\n",
       "      <td>00:08:31</td>\n",
       "      <td>91.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>20</td>\n",
       "      <td>00:29:58</td>\n",
       "      <td>00:14:37</td>\n",
       "      <td>90.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>400</th>\n",
       "      <td>20</td>\n",
       "      <td>00:35:30</td>\n",
       "      <td>00:17:25</td>\n",
       "      <td>78.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>20</td>\n",
       "      <td>00:37:29</td>\n",
       "      <td>00:19:13</td>\n",
       "      <td>77.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>95.9</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         time  \\\n",
       "                                                                          len   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold        \n",
       "False                   identity            0          400                 20   \n",
       "                                            4          400                 20   \n",
       "True                    elu                 0          400                 20   \n",
       "                                                       800                 20   \n",
       "                                            4          400                 20   \n",
       "                                                       800                 20   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                            tmean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:25:21   \n",
       "                                            4          400               00:28:06   \n",
       "True                    elu                 0          400               00:27:36   \n",
       "                                                       800               00:29:58   \n",
       "                                            4          400               00:35:30   \n",
       "                                                       800               00:37:29   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                             tstd   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold            \n",
       "False                   identity            0          400               00:07:25   \n",
       "                                            4          400               00:08:41   \n",
       "True                    elu                 0          400               00:08:31   \n",
       "                                                       800               00:14:37   \n",
       "                                            4          400               00:17:25   \n",
       "                                                       800               00:19:13   \n",
       "\n",
       "                                                                          test  \\\n",
       "                                                                          mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                88.1   \n",
       "                                            4          400                82.8   \n",
       "True                    elu                 0          400                91.4   \n",
       "                                                       800                90.2   \n",
       "                                            4          400                78.3   \n",
       "                                                       800                77.7   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           std   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold         \n",
       "False                   identity            0          400                 5.8   \n",
       "                                            4          400                11.9   \n",
       "True                    elu                 0          400                 4.5   \n",
       "                                                       800                 5.6   \n",
       "                                            4          400                15.0   \n",
       "                                                       800                17.1   \n",
       "\n",
       "                                                                          train  \\\n",
       "                                                                           mean   \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold          \n",
       "False                   identity            0          400                100.0   \n",
       "                                            4          400                100.0   \n",
       "True                    elu                 0          400                100.0   \n",
       "                                                       800                100.0   \n",
       "                                            4          400                 95.6   \n",
       "                                                       800                 95.9   \n",
       "\n",
       "                                                                               \n",
       "                                                                          std  \n",
       "batch_norm_before_merge nonlin_before_merge low_cut_hz max_abs_threshold       \n",
       "False                   identity            0          400                0.0  \n",
       "                                            4          400                0.1  \n",
       "True                    elu                 0          400                0.0  \n",
       "                                                       800                0.0  \n",
       "                                            4          400                8.5  \n",
       "                                                       800                8.9  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_merged_ours = load_data_frame('data/models/paper/ours/epo/merged//', shorten_headers=False)\n",
    "\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_merged_ours.drop('layer_names_to_norms', axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.analysis.stats import perm_mean_diff_test\n",
    "import pandas as pd\n",
    "from braindecode.analysis.pandas_util import round_numeric_columns\n",
    "from braindecode.analysis.stats import wilcoxon_signed_rank, sign_test\n",
    "\n",
    "\n",
    "from braindecode.analysis.pandas_util import restrict, restrict_or_unset, restrict_or_missing_col\n",
    "from braindecode.paper.results import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > 8 Hz comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_ours = load_data_frame('data/models/paper/ours/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_low_freq</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>118.0</th>\n",
       "      <td>14</td>\n",
       "      <td>00:08:42</td>\n",
       "      <td>00:01:42</td>\n",
       "      <td>91.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>98.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <th>118.0</th>\n",
       "      <td>14</td>\n",
       "      <td>00:08:21</td>\n",
       "      <td>00:01:37</td>\n",
       "      <td>90.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">11.0</th>\n",
       "      <th>26.0</th>\n",
       "      <td>14</td>\n",
       "      <td>00:02:07</td>\n",
       "      <td>00:00:21</td>\n",
       "      <td>81.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>94.7</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118.0</th>\n",
       "      <td>14</td>\n",
       "      <td>00:15:51</td>\n",
       "      <td>00:03:14</td>\n",
       "      <td>90.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>98.3</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time                    test       train     \n",
       "                                 len    tmean     tstd  mean   std  mean  std\n",
       "last_low_freq min_freq max_freq                                              \n",
       "10.0          1.0      118.0      14 00:08:42 00:01:42  91.2   9.5  98.7  1.5\n",
       "              7.0      118.0      14 00:08:21 00:01:37  90.9   9.9  98.4  1.9\n",
       "14.0          11.0     26.0       14 00:02:07 00:00:21  81.2  11.7  94.7  4.5\n",
       "                       118.0      14 00:15:51 00:03:14  90.2  10.7  98.3  2.1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csp_ours_for_comp = df_csp_ours[(df_csp_ours.high_width == 8) & \n",
    "                                   (df_csp_ours.max_abs_threshold == 800) &\n",
    "                                  (df_csp_ours.trial_start == 500)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(clean_datasets(df_csp_ours_for_comp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>00:01:17</td>\n",
       "      <td>00:00:11</td>\n",
       "      <td>71.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time                    test       train      \n",
       "   len    tmean     tstd  mean   std  mean   std\n",
       "0   20 00:01:17 00:00:11  71.4  16.1  83.5  10.9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csp_ours_for_comp = df_csp_ours[(df_csp_ours.high_width == 22)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_csp_ours_for_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_bcic = load_data_frame('data/models/paper/bci-competition/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_stop</th>\n",
       "      <th>high_width</th>\n",
       "      <th>last_low_freq</th>\n",
       "      <th>high_overlap</th>\n",
       "      <th>n_selected_features</th>\n",
       "      <th>low_width</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "      <th>low_overlap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <th>8</th>\n",
       "      <th>10.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>20</th>\n",
       "      <th>6</th>\n",
       "      <th>7.0</th>\n",
       "      <th>34.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:33</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>67.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>1.0</th>\n",
       "      <th>34.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:49</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>94.6</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <th>34.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:39</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>67.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>92.6</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">11.0</th>\n",
       "      <th>26.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>66.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>91.1</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:53</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>67.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>92.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>19.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>null</th>\n",
       "      <th>22</th>\n",
       "      <th>19.0</th>\n",
       "      <th>19.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             time  \\\n",
       "                                                                                                              len   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap        \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0            9   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0            9   \n",
       "                                                                               7.0      34.0     3.0            9   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0            9   \n",
       "                                                                                        34.0     3.0            9   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0            9   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                tmean   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap            \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0         00:00:33   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0         00:00:49   \n",
       "                                                                               7.0      34.0     3.0         00:00:39   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0         00:00:25   \n",
       "                                                                                        34.0     3.0         00:00:53   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0         00:00:06   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                 tstd   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap            \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0         00:00:02   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0         00:00:01   \n",
       "                                                                               7.0      34.0     3.0         00:00:01   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0         00:00:01   \n",
       "                                                                                        34.0     3.0         00:00:08   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0         00:00:00   \n",
       "\n",
       "                                                                                                              test  \\\n",
       "                                                                                                              mean   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap         \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0          67.6   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0          68.0   \n",
       "                                                                               7.0      34.0     3.0          67.8   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0          66.7   \n",
       "                                                                                        34.0     3.0          67.6   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0          65.0   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap         \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0          15.1   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0          15.1   \n",
       "                                                                               7.0      34.0     3.0          15.9   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0          17.9   \n",
       "                                                                                        34.0     3.0          14.9   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0          18.0   \n",
       "\n",
       "                                                                                                             train  \\\n",
       "                                                                                                              mean   \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap         \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0          93.6   \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0          94.6   \n",
       "                                                                               7.0      34.0     3.0          92.6   \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0          91.1   \n",
       "                                                                                        34.0     3.0          92.6   \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0          79.6   \n",
       "\n",
       "                                                                                                                    \n",
       "                                                                                                               std  \n",
       "trial_stop high_width last_low_freq high_overlap n_selected_features low_width min_freq max_freq low_overlap        \n",
       "2500       8          10.0          4.0          20                  6         7.0      34.0     3.0           4.1  \n",
       "4000       8          10.0          4.0          20                  6         1.0      34.0     3.0           3.2  \n",
       "                                                                               7.0      34.0     3.0           5.2  \n",
       "                      14.0          4.0          20                  6         11.0     26.0     3.0           5.6  \n",
       "                                                                                        34.0     3.0           5.0  \n",
       "           22         19.0          0.0          null                22        19.0     19.0     0.0          10.8  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csp_bcic_for_comp = df_csp_bcic[(df_csp_bcic.resample_fs == 250) & \n",
    "                                  (df_csp_bcic.trial_start == 500)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(clean_datasets(df_csp_bcic_for_comp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from braindecode.analysis.pandas_util import (load_data_frame,\n",
    "                                              dataset_averaged_frame,\n",
    "                                              remove_columns_with_same_value,\n",
    "                                              remove_indices_with_same_value)\n",
    "\n",
    "df_csp_ours = load_data_frame('data/models/paper/ours/csp/', shorten_headers=False)\n",
    "df_csp_bcic = load_data_frame('data/models/paper/bci-competition/csp/', shorten_headers=False)\n",
    "df_deep_cnt_ours = load_data_frame('data/models/paper/ours/cnt/deep4/', shorten_headers=False)\n",
    "df_deep_cnt_bcic = load_data_frame('data/models/paper/bci-competition/cnt/deep4/', shorten_headers=False)\n",
    "df_shallow_cnt_ours = load_data_frame('data/models/paper/ours/cnt/shallow//', shorten_headers=False)\n",
    "df_shallow_cnt_bcic = load_data_frame('data/models/paper/bci-competition/cnt/shallow//', shorten_headers=False)\n",
    "\n",
    "df_deep_epo_ours = load_data_frame('data/models/paper/ours/epo/deep4/', shorten_headers=False)\n",
    "df_deep_epo_bcic = load_data_frame('data/models/paper/bci-competition/epo/deep4/', shorten_headers=False)\n",
    "df_shallow_epo_ours = load_data_frame('data/models/paper/ours/epo/shallow//', shorten_headers=False)\n",
    "df_shallow_epo_bcic = load_data_frame('data/models/paper/bci-competition/epo/shallow//', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged_cnt_bcic = load_data_frame('data/models/paper/bci-competition//cnt/merged//', shorten_headers=False)\n",
    "df_merged_epo_bcic = load_data_frame('data/models/paper/bci-competition//epo/merged//', shorten_headers=False)\n",
    "df_merged_cnt_ours = load_data_frame('data/models/paper/ours/cnt/merged//', shorten_headers=False)\n",
    "df_merged_epo_ours = load_data_frame('data/models/paper/ours/epo/merged//', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from braindecode.paper.results import clean_datasets\n",
    "def add_p_vals_to_df_row(df, test_a, test_b, n_diffs_for_large=2**20):\n",
    "    assert len(test_a) == len(test_b)\n",
    "    if len(test_a) > 20:\n",
    "        assert len(test_a) == 29 or len(test_a) == 23\n",
    "        p_val = perm_mean_diff_test(test_a,test_b, n_diffs=n_diffs_for_large)\n",
    "    else:\n",
    "        assert len(test_a) == 9 or len(test_a) == 20 or len(test_a) == 14 \n",
    "        p_val = perm_mean_diff_test(test_a,test_b)\n",
    "    p_val_wilc = wilcoxon_signed_rank(test_a, test_b)\n",
    "    p_val_sign = sign_test(test_a, test_b)\n",
    "    df['rand'] = p_val\n",
    "    df['wilc'] = p_val_wilc\n",
    "    df['sign'] = p_val_sign    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csp_no_standardize(df):\n",
    "    df = df[((df.standardize_filt_cnt == False) | (df.standardize_filt_cnt == '-')) &\n",
    "           ((df.standardize_epo == False) | (df.standardize_epo == '-')) &\n",
    "           ((df.standardize_cnt == False) | (df.standardize_cnt == '-')) &\n",
    "           ((df.standardize == False) | (df.standardize == '-'))]\n",
    "    return df\n",
    "\n",
    "def csp_no_standardize_new(df):\n",
    "    df = csp_no_standardize(df)\n",
    "    df = df[df.standardize == '-']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tstd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_stop</th>\n",
       "      <th>trial_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <th>500</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:33</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>67.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4000</th>\n",
       "      <th>-500</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:44</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>57.1</td>\n",
       "      <td>10.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:41</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>61.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>90.3</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>9</td>\n",
       "      <td>00:00:39</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>67.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>92.6</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time                    test       train     \n",
       "                        len    tmean     tstd  mean   std  mean  std\n",
       "trial_stop trial_start                                              \n",
       "2500        500           9 00:00:33 00:00:02  67.6  15.1  93.6  4.1\n",
       "4000       -500           9 00:00:44 00:00:02  57.1  10.3  88.9  6.6\n",
       "            0             9 00:00:41 00:00:01  61.3  14.3  90.3  6.2\n",
       "            500           9 00:00:39 00:00:01  67.8  15.9  92.6  5.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = df_csp_bcic.copy()\n",
    "df_valid = df_valid[(df_valid.resample_fs == 250) & (df_valid.max_freq == 34) & (df_valid.min_freq == 7)]\n",
    "df_valid = df_valid[df_valid.low_bound == 0]\n",
    "df_valid = df_valid.sort_values(by='dataset_filename')\n",
    "\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_theirs</th>\n",
       "      <th>test_ours</th>\n",
       "      <th>diff</th>\n",
       "      <th>rand</th>\n",
       "      <th>wilc</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.01</td>\n",
       "      <td>67.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_theirs  test_ours  diff     rand      wilc  sign\n",
       "0        67.01      67.59  0.58  0.78125  0.734375   1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val_theirs = [79.16,52.08,83.33,62.15,54.51,39.24,83.33,82.64,66.67]\n",
    "\n",
    "test_val_ours_2500 = df_valid[df_valid.trial_stop == 2500].test\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['test_theirs'] = [np.mean(test_val_theirs)]\n",
    "df['test_ours'] = [np.mean(test_val_ours_2500)]\n",
    "df['diff'] = [np.mean(test_val_ours_2500) - np.mean(test_val_theirs)]\n",
    "df = round_numeric_columns(df, 2)\n",
    "add_p_vals_to_df_row(df, test_val_theirs, test_val_ours_2500)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_theirs</th>\n",
       "      <th>test_ours</th>\n",
       "      <th>diff</th>\n",
       "      <th>rand</th>\n",
       "      <th>wilc</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.01</td>\n",
       "      <td>67.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_theirs  test_ours  diff      rand      wilc  sign\n",
       "0        67.01      67.82  0.81  0.757812  0.734375   1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val_ours_4000 = df_valid[(df_valid.trial_stop == 4000) & (df_valid.trial_start == 500)].test\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['test_theirs'] = [np.mean(test_val_theirs)]\n",
    "df['test_ours'] = [np.mean(test_val_ours_4000)]\n",
    "df['diff'] = [np.mean(test_val_ours_4000) - np.mean(test_val_theirs)]\n",
    "df = round_numeric_columns(df, 2)\n",
    "add_p_vals_to_df_row(df, test_val_theirs, test_val_ours_4000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.analysis.pandas_util import restrict_if_existing_and_not_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schirrmr/braindecode/code/braindecode/analysis/pandas_util.py:291: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if '-' in np.array(df[key]):\n"
     ]
    }
   ],
   "source": [
    "from braindecode.paper.results import *\n",
    "all_df = pd.DataFrame()\n",
    "for dataset in ('bcic', 'ours'):\n",
    "    for net in ('shallow', 'deep5', 'merged'):\n",
    "        for training in 'epo', 'cnt':\n",
    "            for band in ['>0', '>4', ]:\n",
    "                for clean in (True, False):\n",
    "                    for trial_start in (-500, ):#0,500\n",
    "                        for max_abs_val_threshold in (800,):#400,\n",
    "                            if max_abs_val_threshold == 400 and trial_start != -500:\n",
    "                                continue\n",
    "                            if training == 'cnt':\n",
    "                                trial_start_net = trial_start + 2000\n",
    "                            else:\n",
    "                                trial_start_net = trial_start\n",
    "                            if dataset == 'bcic':\n",
    "                                dfc = df_csp_bcic\n",
    "                            else:\n",
    "                                assert dataset == 'ours'\n",
    "                                dfc = df_csp_ours\n",
    "                            if dataset == 'bcic' and net == 'shallow' and training == 'cnt':\n",
    "                                dfn = df_shallow_cnt_bcic\n",
    "                            elif dataset == 'bcic' and net == 'shallow' and training == 'epo':\n",
    "                                dfn = df_shallow_epo_bcic\n",
    "                            elif dataset == 'bcic' and net == 'deep5' and training == 'cnt':\n",
    "                                dfn = df_deep_cnt_bcic\n",
    "                            elif dataset == 'bcic' and net == 'deep5' and training == 'epo':\n",
    "                                dfn = df_deep_epo_bcic\n",
    "                            elif dataset == 'bcic' and net == 'merged' and training == 'cnt':\n",
    "                                dfn = df_merged_cnt_bcic\n",
    "                            elif dataset == 'bcic' and net == 'merged' and training == 'epo':\n",
    "                                dfn = df_merged_epo_bcic\n",
    "                            elif dataset == 'ours' and net == 'shallow' and training == 'cnt':\n",
    "                                dfn = df_shallow_cnt_ours\n",
    "                            elif dataset == 'ours' and net == 'shallow' and training == 'epo':\n",
    "                                dfn = df_shallow_epo_ours\n",
    "                            elif dataset == 'ours' and net == 'deep5' and training == 'cnt':\n",
    "                                dfn = df_deep_cnt_ours\n",
    "                            elif dataset == 'ours' and net == 'deep5' and training == 'epo':\n",
    "                                dfn = df_deep_epo_ours\n",
    "                            elif dataset == 'ours' and net == 'merged' and training == 'cnt':\n",
    "                                dfn = df_merged_cnt_ours\n",
    "                            elif dataset == 'ours' and net == 'merged' and training == 'epo':\n",
    "                                dfn = df_merged_epo_ours\n",
    "                            else:\n",
    "                                raise ValueError(\"Unknown combination {:s} {:s} {:s}\".format(\n",
    "                                    dataset, net, training))\n",
    "                            if clean:\n",
    "                                dfn = clean_datasets(dfn)\n",
    "                                dfc = clean_datasets(dfc)\n",
    "\n",
    "                            if band == '>0':\n",
    "                                this_dfn = above_0(dfn)\n",
    "                                this_dfc = csp_above_0(dfc)\n",
    "                            elif band == '>4':\n",
    "                                this_dfn = above_4(dfn)\n",
    "                                this_dfc = csp_above_4(dfc)\n",
    "                            elif band == '0-4':\n",
    "                                this_dfn = from_0_to_4(dfn)\n",
    "                                this_dfc = csp_0_to_4(dfc)\n",
    "\n",
    "\n",
    "                            if net == 'deep5' and training == 'epo':\n",
    "                                this_dfn = deep5_main_comp(this_dfn)\n",
    "                            elif net == 'deep5' and training == 'cnt':\n",
    "                                this_dfn = deep5_cnt_main_comp(this_dfn)\n",
    "                            elif net =='shallow' and training == 'epo':\n",
    "                                this_dfn = shallow_main_comp(this_dfn)\n",
    "                            elif net =='shallow' and training == 'cnt':\n",
    "                                this_dfn = shallow_cnt_main_comp(this_dfn)\n",
    "                            elif net == 'merged':\n",
    "                                this_dfn = merged_main_comp(this_dfn)\n",
    "                            else:\n",
    "                                raise ValueError(\"Unknown combination\")\n",
    "\n",
    "\n",
    "                            this_dfc = main_comp_csp(this_dfc)\n",
    "                            this_dfn = this_dfn[this_dfn.max_abs_threshold == max_abs_val_threshold]\n",
    "                            if dataset == 'ours':\n",
    "                                this_dfc = this_dfc[this_dfc.max_abs_threshold == max_abs_val_threshold]\n",
    "                                \n",
    "                            this_dfn = this_dfn[this_dfn.trial_start == trial_start_net]\n",
    "                            trial_start_csp = 500 # hack to not have to cahnge logic of loop\n",
    "                            this_dfc = this_dfc[this_dfc.trial_start == trial_start_csp]\n",
    "                            this_dfn = restrict_if_existing_and_not_unique(this_dfn, variant='b')\n",
    "                            if training == 'epo':\n",
    "                                this_dfn = this_dfn[this_dfn.max_increasing_epochs == 160]\n",
    "                                this_dfn = restrict_if_existing_and_not_unique(this_dfn, monitors='trial_monitors')\n",
    "                            else:\n",
    "                                assert training == 'cnt'\n",
    "                                this_dfn = this_dfn[this_dfn.max_increasing_epochs == 80]\n",
    "\n",
    "                            if dataset == 'bcic' and net == 'deep5' and (\n",
    "                                training == 'epo' or (band == '>0' or band == '>4')):\n",
    "                                this_dfn = this_dfn[this_dfn.layers == 'deep_5']\n",
    "\n",
    "\n",
    "                            if dataset == 'bcic':\n",
    "                                assert len(this_dfc) == 9, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                                assert len(this_dfn) == 9, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                            elif dataset == 'ours' and clean:\n",
    "                                assert len(this_dfc) == 14, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                                assert len(this_dfn) == 14, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                            elif dataset == 'ours' and (not clean):\n",
    "                                assert len(this_dfc) == 20, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                                assert len(this_dfn) == 20, \"wrong length: {:d} ({:s})\".format(\n",
    "                                    len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                            else:\n",
    "                                raise ValueError(\"Unknown combination\")\n",
    "\n",
    "\n",
    "                            this_dfn = remove_columns_with_same_value(this_dfn)\n",
    "                            this_dfn['clean'] = clean\n",
    "                            this_dfn['net'] = net\n",
    "                            this_dfn['train_type'] = training\n",
    "                            this_dfn['freq'] = band\n",
    "                            this_dfn['dataset'] = dataset\n",
    "                            this_dfn['trial_start'] = trial_start\n",
    "                            this_dfn['max_abs_threshold'] = max_abs_val_threshold\n",
    "\n",
    "                            all_df = all_df.append(this_dfn)\n",
    "                            if net == 'shallow' and training == 'epo': # only add csp once, not several times => for both nets :))\n",
    "                                this_dfc = remove_columns_with_same_value(this_dfc)\n",
    "                                this_dfc['clean'] = clean\n",
    "                                this_dfc['net'] = 'csp'\n",
    "                                this_dfc['freq'] = band\n",
    "                                this_dfc['train_type'] = training\n",
    "                                this_dfc['dataset'] = dataset\n",
    "                                this_dfc['trial_start'] = trial_start_csp\n",
    "                                this_dfc['max_abs_threshold'] = max_abs_val_threshold\n",
    "                                all_df = all_df.append(this_dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "assert len(all_df) == ((3*2*2 + 2) * 29 + (3*2*2 + 2) * 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbci-competition\u001b[0m/  \u001b[01;34mbefore-batch-norm\u001b[0m/  \u001b[01;34mcsp\u001b[0m/  \u001b[01;34mours\u001b[0m/  \u001b[01;34mours-before-cz-0\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data/models/paper/before-trial-start-reruns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stricter trial cleaning with max abs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:bcic 0-4 deep5 cnt (clean: False)\n",
      "/home/schirrmr/motor-imagery/ipython-notebooks-metagpu/venv/local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/schirrmr/motor-imagery/ipython-notebooks-metagpu/venv/local/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unbound method cython_function_or_method object must be called with Timedelta instance as first argument (got NaTType instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-aad30d71345c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m                             \u001b[0mthis_row_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_row_net\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthis_row_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                         df_compare = compare_net_csp(this_row_net,this_row_csp, net,freq,dataset,\n\u001b[1;32m---> 31\u001b[1;33m                                                     max_n_p_vals=17, with_csp_acc=True)\n\u001b[0m\u001b[0;32m     32\u001b[0m                         \u001b[0mdf_compare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[0mdf_compare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/schirrmr/braindecode/code/braindecode/paper/results.pyc\u001b[0m in \u001b[0;36mcompare_net_csp\u001b[1;34m(df_net, df_csp, name, freq, dataset, with_csp_acc, with_std, with_std_error, max_n_p_vals)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wilc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_val_wilc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sign'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_val_sign\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     \u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_net'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     assert len(df_merged) == len(df_csp), (\n",
      "\u001b[1;31mTypeError\u001b[0m: unbound method cython_function_or_method object must be called with Timedelta instance as first argument (got NaTType instance instead)"
     ]
    }
   ],
   "source": [
    "all_400_max_df = pd.DataFrame()\n",
    "for clean in (False, True):\n",
    "        trial_start = -500\n",
    "        max_abs_threshold = 400\n",
    "\n",
    "\n",
    "        all_labels = []\n",
    "        sig_count_strong = []\n",
    "        sig_count_weak = []\n",
    "        for dataset in ('bcic', 'ours', 'combined'):\n",
    "            for freq in ('0-4', '>0', '>4'):\n",
    "                for net in ('deep5', 'shallow'):\n",
    "                    for train_type in ('cnt', 'epo',):\n",
    "                        log.info(\"{:s} {:s} {:s} {:s} (clean: {:s})\".format(\n",
    "                                dataset, freq,net, train_type, str(clean)))\n",
    "                        this_row_net = all_df[(all_df.freq == freq) &\n",
    "                                               (all_df.train_type == train_type) &\n",
    "                                               (all_df.net == net) &\n",
    "                                                (all_df.clean == clean) &\n",
    "                                         (all_df.trial_start == trial_start) &\n",
    "                                             (all_df.max_abs_threshold == max_abs_threshold)]\n",
    "                        this_row_csp = all_df[(all_df.freq == freq) &\n",
    "                                               (all_df.net == 'csp') &\n",
    "                                                (all_df.clean == clean) &\n",
    "                                         (all_df.trial_start == 500) &\n",
    "                                             (all_df.max_abs_threshold == max_abs_threshold)]\n",
    "                        if dataset != 'combined':\n",
    "                            this_row_csp = this_row_csp[this_row_csp.dataset == dataset]\n",
    "                            this_row_net = this_row_net[this_row_net.dataset == dataset]\n",
    "                        df_compare = compare_net_csp(this_row_net,this_row_csp, net,freq,dataset,\n",
    "                                                    max_n_p_vals=17, with_csp_acc=True)\n",
    "                        df_compare['clean'] = clean\n",
    "                        df_compare['train_type'] = train_type\n",
    "                        all_400_max_df = all_400_max_df.append(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png' \n",
    "\n",
    "for clean in (False, True):\n",
    "        trial_start = -500\n",
    "        max_abs_threshold = 400\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "        plt.plot([40,100], [40,100], color='black', label='', linestyle='--', lw=1)\n",
    "\n",
    "        all_labels = []\n",
    "        sig_count_strong = []\n",
    "        sig_count_weak = []\n",
    "        for dataset in ('bcic', 'ours', 'combined'):\n",
    "            for freq in ('0-4', '>0', '>4'):\n",
    "                for net in ('deep5', 'shallow'):\n",
    "                    for train_type in ('cnt', 'epo',):\n",
    "                        this_row = all_400_max_df[\n",
    "                            (all_400_max_df.dataset == dataset) &\n",
    "                            (all_400_max_df.freq == freq) &\n",
    "                            (all_400_max_df.name == net) &\n",
    "                            (all_400_max_df.train_type == train_type) &\n",
    "                            (all_400_max_df.clean == clean)]\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        markerfacecolor = 'None'\n",
    "                        if 'bcic' == dataset:\n",
    "                            markersize=7\n",
    "                        elif 'ours' == dataset:\n",
    "                            markersize=10\n",
    "                        elif 'combined' == dataset:\n",
    "                            markersize=13 \n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row.test_csp\n",
    "                        test_net = this_row.test_net\n",
    "\n",
    "\n",
    "                        plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        # add significance star\n",
    "                        if this_row['rand'] < 0.05:\n",
    "                            if this_row['rand'] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row['rand'] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = (10, -4), fontsize=16,\n",
    "                                textcoords = 'offset points', ha = 'left', va = 'center',)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "\n",
    "        plt.ylabel('ConvNet Accuracy [%]', fontsize=18)\n",
    "\n",
    "        circle = plt.Circle((83,83), 5, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "        plt.gca().add_artist(circle)\n",
    "\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles[12:30], (\n",
    "                                   'Deep 0-4 Hz (cropped)', \n",
    "                                   'Deep 0-4 Hz (trial)',\n",
    "                                   'Shallow 0-4 Hz (cropped)',\n",
    "                                   'Shallow 0-4 Hz (trial)',\n",
    "                                   'Deep 0-125 Hz (cropped)', \n",
    "                                   'Deep 0-125 Hz (trial)',\n",
    "                                   'Shallow 0-125 Hz (cropped)',\n",
    "                                   'Shallow 0-125 Hz (trial)',\n",
    "                                   'Deep 4-125 Hz (cropped)', \n",
    "                                   'Deep 4-125 Hz (trial)',\n",
    "                                   'Shallow 4-125 Hz (cropped)',\n",
    "                                   'Shallow 4-125 Hz (trial)',),\n",
    "                  bbox_to_anchor=(1.55,1),fontsize=14)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.annotate(u\"$N_{{ConvNet>FBCSP}}$ = {:d}\".format(np.sum(np.array(sig_count_strong) == 1)\n",
    "                                                    + np.sum(np.array(sig_count_weak) == 1)),xy=(42,96),\n",
    "                    fontsize=22)\n",
    "        plt.annotate(u\"$N_{{ConvNet<FBCSP}}$ = {:d}\".format(np.sum(np.array(sig_count_strong) == -1)\n",
    "                                                    + np.sum(np.array(sig_count_weak) == -1)),xy=(98,44),\n",
    "                    fontsize=22, ha='right')\n",
    "\n",
    "        # We change the fontsize of minor ticks label \n",
    "        plt.gca().tick_params(axis='both', which='major', labelsize=18)\n",
    "        clean_str = 'Restricted subjects' if clean else 'All subjects'\n",
    "        plt.title('{:s} Max Abs 400'.format(clean_str), fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove max abs threshold == 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df = all_df[all_df.max_abs_threshold == 800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot overall stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Make comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets reduce to proper comparison\n",
    "#all_df = all_df[((all_df.net != 'csp') & (all_df.trial_start == -500)) |\n",
    "#      ((all_df.net == 'csp') & (all_df.trial_start == 500))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "all_compared = pd.DataFrame()\n",
    "param_keys = ['dataset', 'freq', 'net',  'train_type', 'clean']\n",
    "all_groups = all_df.groupby(param_keys)\n",
    "\n",
    "for name, group in all_groups:\n",
    "    assert len(group['freq'].unique()) == 1\n",
    "    freq = group['freq'].iloc[0]\n",
    "    assert len(group['dataset'].unique()) == 1\n",
    "    dataset = group['dataset'].iloc[0]\n",
    "    assert len(group['net'].unique()) == 1\n",
    "    net = group['net'].iloc[0]\n",
    "    assert len(group['clean'].unique()) == 1\n",
    "    clean = group['clean'].iloc[0]\n",
    "    assert len(group['train_type'].unique()) == 1\n",
    "    train_type = group['train_type'].iloc[0]\n",
    "    if net == 'csp': continue\n",
    "    #if net != 'merged': continue\n",
    "    if group.max_abs_threshold.iloc[0] == 400: continue\n",
    "    csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                (all_df.dataset == dataset) &\n",
    "                (all_df.clean == clean)]\n",
    "    df_compare = compare_net_csp(group, csp, net, freq, dataset, with_csp_acc=True, with_std=True,\n",
    "                                with_std_error=True)   \n",
    "    df_compare['clean'] = clean\n",
    "    df_compare['train_type'] = train_type\n",
    "    all_compared = all_compared.append(df_compare)\n",
    "    log.info(\"{:s} {:s} {:s} {:s}\".format(dataset, freq,net, str(clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add combined set comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### look at jitter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "param_keys = ['freq', 'net',  'train_type', 'clean', 'max_abs_threshold']\n",
    "all_groups = all_df.groupby(param_keys)\n",
    "\n",
    "all_test_net = []\n",
    "all_test_csp = []\n",
    "rng = RandomState(394834)\n",
    "for wanted_train_type in ('cnt', 'epo'):\n",
    "    for wanted_net in ('deep5', 'shallow'):\n",
    "        plt.figure(figsize=(4,2))\n",
    "        \n",
    "        offset = 0\n",
    "        for name, group in all_groups:\n",
    "            assert len(group['freq'].unique()) == 1\n",
    "            freq = group['freq'].iloc[0]\n",
    "            assert len(group['net'].unique()) == 1\n",
    "            net = group['net'].iloc[0]\n",
    "            assert len(group['clean'].unique()) == 1\n",
    "            clean = group['clean'].iloc[0]\n",
    "            assert len(group['train_type'].unique()) == 1\n",
    "            train_type = group['train_type'].iloc[0]\n",
    "            if clean == False: continue\n",
    "            if net == 'csp': continue\n",
    "            if net != wanted_net: continue\n",
    "            if train_type != wanted_train_type: continue\n",
    "            csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                        (all_df.clean == clean)]\n",
    "            assert (len(csp) == 29 and not clean) or (len(csp) == 23 and clean)\n",
    "            df_merged = group.merge(csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "\n",
    "            test_acc_net = np.array(df_merged['test_net'])\n",
    "            test_acc_csp = np.array(df_merged['test_csp'])\n",
    "            all_test_net.append(test_acc_net)\n",
    "            all_test_csp.append(test_acc_csp)\n",
    "            diffs = test_acc_net - test_acc_csp\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            else:\n",
    "                assert freq == '0-4'\n",
    "                color = seaborn.color_palette()[3]\n",
    "            markerfacecolor = 'None'\n",
    "            if 'cnt' == train_type:\n",
    "                markerfacecolor = color\n",
    "\n",
    "            plt.plot(\n",
    "                    rng.randn(len(diffs)) * 0.05 + offset,\n",
    "                        diffs, color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                    markersize=5,markeredgecolor=color, markerfacecolor=markerfacecolor, \n",
    "                     markeredgewidth=1)\n",
    "            plt.errorbar(offset+0.25, np.mean(diffs), yerr=np.std(diffs), ecolor=color,\n",
    "                     marker=marker, linestyle='None',\n",
    "                markersize=8,markeredgecolor=color, markerfacecolor=markerfacecolor, \n",
    "                             markeredgewidth=1)\n",
    "            offset += 1\n",
    "            #plt.xlabel('FBCSP Accuracy [%]')\n",
    "        plt.ylabel('Difference ConvNet-FBCSP [%]')\n",
    "        plt.ylim(-40,40)\n",
    "        plt.axhline(y=0, linestyle='--', color=(0.3,0.3,0.3,0.3))\n",
    "        plt.xticks(range(0,3), ['0-4 Hz', '0-125 Hz', '4-125 Hz'])\n",
    "        title_str = wanted_net.strip('5').capitalize()\n",
    "        if wanted_train_type == 'cnt':\n",
    "            title_str += \" (cropped)\"\n",
    "        else:\n",
    "            assert wanted_train_type == 'epo'\n",
    "            title_str += \" (trial)\"\n",
    "        plt.title(title_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Subject All Dots CSP vs Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "param_keys = ['freq', 'net',  'train_type', 'clean']\n",
    "all_groups = all_df.groupby(param_keys)\n",
    "\n",
    "all_test_net = []\n",
    "all_test_csp = []\n",
    "rng = RandomState(394834)\n",
    "plt.figure(figsize=(7,7))\n",
    "for wanted_train_type in ('cnt', 'epo'):\n",
    "    for wanted_net in ('deep5', 'shallow'):\n",
    "        \n",
    "        offset = 0\n",
    "        for name, group in all_groups:\n",
    "            assert len(group['freq'].unique()) == 1\n",
    "            freq = group['freq'].iloc[0]\n",
    "            assert len(group['net'].unique()) == 1\n",
    "            net = group['net'].iloc[0]\n",
    "            assert len(group['clean'].unique()) == 1\n",
    "            clean = group['clean'].iloc[0]\n",
    "            assert len(group['train_type'].unique()) == 1\n",
    "            train_type = group['train_type'].iloc[0]\n",
    "            if clean == True: continue\n",
    "            if net == 'csp': continue\n",
    "            if net != wanted_net: continue\n",
    "            if train_type != wanted_train_type: continue\n",
    "            csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                        (all_df.clean == clean)]\n",
    "            assert (len(csp) == 29 and not clean) or (len(csp) == 23 and clean)\n",
    "            df_merged = group.merge(csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "\n",
    "            test_acc_net = np.array(df_merged['test_net'])\n",
    "            test_acc_csp = np.array(df_merged['test_csp'])\n",
    "            all_test_net.append(test_acc_net)\n",
    "            all_test_csp.append(test_acc_csp)\n",
    "            diffs = test_acc_net - test_acc_csp\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            else:\n",
    "                assert freq == '0-4'\n",
    "                color = seaborn.color_palette()[3]\n",
    "            markerfacecolor = 'None'\n",
    "            if 'cnt' == train_type:\n",
    "                markerfacecolor = color\n",
    "\n",
    "            plt.plot(\n",
    "                    test_acc_csp, test_acc_net, color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                    markersize=5,markeredgecolor=color, markerfacecolor=markerfacecolor, \n",
    "                     markeredgewidth=1)\n",
    "            #plt.xlabel('FBCSP Accuracy [%]')\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[12:30], (\n",
    "                               'Deep 0-4 Hz (cropped)', \n",
    "                               'Deep 0-4 Hz (trial)',\n",
    "                               'Shallow 0-4 Hz (cropped)',\n",
    "                               'Shallow 0-4 Hz (trial)',\n",
    "                               'Deep 0-125 Hz (cropped)', \n",
    "                               'Deep 0-125 Hz (trial)',\n",
    "                               'Shallow 0-125 Hz (cropped)',\n",
    "                               'Shallow 0-125 Hz (trial)',\n",
    "                               'Deep 4-125 Hz (cropped)', \n",
    "                               'Deep 4-125 Hz (trial)',\n",
    "                               'Shallow 4-125 Hz (cropped)',\n",
    "                               'Shallow 4-125 Hz (trial)',),\n",
    "              bbox_to_anchor=(1.55,1),fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "\n",
    "    plt.ylabel('ConvNet Accuracy [%]', fontsize=18)\n",
    "\n",
    "    # We change the fontsize of minor ticks label \n",
    "    plt.gca().tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.title('All Subjects', fontsize=16)\n",
    "    plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add combined set comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "param_keys = ['freq', 'net',  'train_type', 'clean']\n",
    "all_groups = all_df.groupby(param_keys)\n",
    "\n",
    "for name, group in all_groups:\n",
    "    assert len(group['freq'].unique()) == 1\n",
    "    freq = group['freq'].iloc[0]\n",
    "    assert len(group['net'].unique()) == 1\n",
    "    net = group['net'].iloc[0]\n",
    "    assert len(group['clean'].unique()) == 1\n",
    "    clean = group['clean'].iloc[0]\n",
    "    assert len(group['train_type'].unique()) == 1\n",
    "    train_type = group['train_type'].iloc[0]\n",
    "    if net == 'csp': continue\n",
    "    #if net != 'merged': continue\n",
    "    log.info(\"{:s} {:s} {:s} (clean: {:s})\".format(freq,net, train_type, str(clean)))\n",
    "    csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                (all_df.clean == clean)]\n",
    "    assert (len(csp) == 29 and not clean) or (len(csp) == 23 and clean)\n",
    "    df_compare = compare_net_csp(group, csp, net, freq, 'combined', with_csp_acc=True, with_std=True,\n",
    "                                with_std_error=True)\n",
    "    df_compare['clean'] = clean\n",
    "    df_compare['train_type'] = train_type\n",
    "    all_compared = all_compared.append(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') & \n",
    "             (all_compared.clean ==False) & (all_compared.freq != '0-4')].sort_values(by='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') & \n",
    "             (all_compared.clean ==False) & (all_compared.freq != '0-4') &\n",
    "            (all_compared.name == 'merged')].sort_values(by='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') & \n",
    "             (all_compared.clean ==True) & (all_compared.freq != '0-4') &\n",
    "            (all_compared.name == 'merged')].sort_values(by='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') & \n",
    "             (all_compared.clean ==True) & (all_compared.freq != '0-4')].sort_values(by='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.train_type == 'cnt') &\n",
    "            (all_compared.dataset == 'combined') &\n",
    "            (all_compared.freq != '0-4') &\n",
    "            (all_compared.clean == False)].sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.train_type == 'cnt') &\n",
    "            (all_compared.dataset == 'combined') &\n",
    "            (all_compared.freq != '0-4') &\n",
    "            (all_compared.clean == True)].sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_compared.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.name != 'merged') &\n",
    "            (all_compared.freq != '0-4') &\n",
    "            (all_compared.clean == True) &\n",
    "            (all_compared.train_type == 'cnt')].sort_values(\n",
    "    by='name', kind='mergesort').sort_values(by='freq', kind='mergesort').sort_values(by='dataset', kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.name != 'merged') &\n",
    "            (all_compared.freq != '0-4') &\n",
    "            (all_compared.clean == True)].sort_values(by='train_type', kind='mergesort').sort_values(\n",
    "    by='name', kind='mergesort').sort_values(by='freq', kind='mergesort').sort_values(by='dataset', kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot with only one variant but all dots as scatter stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') &\n",
    "                                       (all_compared.train_type == 'cnt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLBT to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "function makeSVGDownloadable() {\n",
    "    $('body').on('click', 'svg', function(){\n",
    "        var svg = this.outerHTML;\n",
    "        var b64 = btoa(svg); // or use btoa if supported\n",
    "        var linkToSVG = $(\"<a href-lang='image/svg+xml' href='data:image/svg+xml;base64,\\n\" + b64 +\n",
    "                          \"'title='file.svg' target='blank'>Download</a>\");\n",
    "        $(this).after(linkToSVG);});\n",
    "}\n",
    "makeSVGDownloadable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                fig = plt.figure(figsize=(3.5,3.5))\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared[(all_compared.dataset == dataset) &\n",
    "                                               (all_compared.freq == freq) &\n",
    "                                               (all_compared.train_type == train_type) &\n",
    "                                               (all_compared.name == net) &\n",
    "                                                (all_compared.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "\n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.train_type == train_type) &\n",
    "                                   (all_df.net == net) &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "\n",
    "                plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "\n",
    "                net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                y_label_str = \"{:s} ConvNet\\n{:d}-$f_{{end}}$ Hz Accuracy [%]\".format(net_str, \n",
    "                                                              int(freq[1]))\n",
    "                plt.ylabel(y_label_str, fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        fig, axes = plt.subplots(2,2,figsize=(6.5,6.5), sharex=True, sharey=True)\n",
    "        axes = np.array(axes).flatten()\n",
    "        i_plot = 0\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared[(all_compared.dataset == dataset) &\n",
    "                                               (all_compared.freq == freq) &\n",
    "                                               (all_compared.train_type == train_type) &\n",
    "                                               (all_compared.name == net) &\n",
    "                                                (all_compared.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "                        plt.sca(axes[i_plot])\n",
    "                        i_plot += 1\n",
    "                        \n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.train_type == train_type) &\n",
    "                                   (all_df.net == net) &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "                \n",
    "                \n",
    "                if i_plot > 2:\n",
    "                    plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "                if i_plot <= 2:\n",
    "                    net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                    title_str = \"{:s} ConvNet\".format(net_str)\n",
    "                    plt.title(title_str, fontsize=18, y=1.05)\n",
    "                \n",
    "                if i_plot % 2 == 1:\n",
    "                    y_label_str = u'{:d}—$f_{{end}}$ Hz\\nAccuracy[%]'.format(int(freq[1]))\n",
    "                    #plt.ylabel(y_label_str, fontsize=18)\n",
    "                    plt.text(-10,60,y_label_str, va='center', rotation=90,\n",
    "                            fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        fig, axes = plt.subplots(2,2,figsize=(6.5,6.5), sharex=True, sharey=True)\n",
    "        axes = np.array(axes).flatten()\n",
    "        i_plot = 0\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared_past[(all_compared_past.dataset == dataset) &\n",
    "                                               (all_compared_past.freq == freq) &\n",
    "                                               (all_compared_past.train_type == train_type) &\n",
    "                                               (all_compared_past.name == net) &\n",
    "                                                (all_compared_past.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "                        plt.sca(axes[i_plot])\n",
    "                        i_plot += 1\n",
    "                        \n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df_past[\n",
    "                                   (all_df_past.freq == freq) &\n",
    "                                   (all_df_past.train_type == train_type) &\n",
    "                                   (all_df_past.net == net) &\n",
    "                                    (all_df_past.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "                \n",
    "                \n",
    "                if i_plot > 2:\n",
    "                    plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "                if i_plot <= 2:\n",
    "                    net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                    title_str = \"{:s} ConvNet\".format(net_str)\n",
    "                    plt.title(title_str, fontsize=18, y=1.05)\n",
    "                \n",
    "                if i_plot % 2 == 1:\n",
    "                    y_label_str = u'{:d}—$f_{{end}}$ Hz\\nAccuracy[%]'.format(int(freq[1]))\n",
    "                    #plt.ylabel(y_label_str, fontsize=18)\n",
    "                    plt.text(-10,60,y_label_str, va='center', rotation=90,\n",
    "                            fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                #plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                #            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "rng = RandomState(39884934)\n",
    "plt.figure(figsize=(8,3))\n",
    "rands = rng.randn(23) #rng.randn(len(diffs))\n",
    "offset = 0\n",
    "for freq in ('>0', '>4'):\n",
    "    for net in ('deep5', 'shallow'):\n",
    "        this_row = df_cnt_epo[(df_cnt_epo.dataset == 'combined') &\n",
    "                             (df_cnt_epo.freq == freq) &\n",
    "                             (df_cnt_epo.net == net)]\n",
    "        label = 'dummy'\n",
    "        if net == 'deep5':\n",
    "            marker = 'o'\n",
    "        else:\n",
    "            assert net == 'shallow'\n",
    "            marker = '^'\n",
    "        if '0-4' == freq:\n",
    "            color = seaborn.color_palette()[3]\n",
    "        elif '>0' == freq:\n",
    "            color = seaborn.color_palette()[0]\n",
    "        elif '>4' == freq:\n",
    "            color = seaborn.color_palette()[1]\n",
    "        \n",
    "\n",
    "\n",
    "        cnt_test = this_row['test_cnt_subjects'][0]\n",
    "        epo_test = this_row['test_epo_subjects'][0]\n",
    "        diffs = cnt_test - epo_test\n",
    "        # try plotting ours and bcic with different marker sizes, quite hacky(first 14 shouldbe ours)\n",
    "        # not doing anymore\n",
    "        assert clean_trial_sample\n",
    "        plt.plot(rands[:14] * 0.05 + offset - 0.2,\n",
    "                diffs[:14], color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                markersize=8) #markersize 8\n",
    "        plt.plot(rands[14:] * 0.05 + offset - 0.2,\n",
    "                diffs[14:], color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                markersize=8)\n",
    "        plt.errorbar(offset, this_row['diff'][0], color=color,\n",
    "                     yerr=this_row['std'][0], marker=marker,\n",
    "                    markersize=14, label=label)\n",
    "\n",
    "        if this_row['wilc'][0] < 0.05:\n",
    "            if this_row['wilc'][0] < 0.001:\n",
    "                signicance_str = '***'\n",
    "            elif this_row['wilc'][0] < 0.01:\n",
    "                signicance_str = '**'\n",
    "            else:\n",
    "                signicance_str = '*'\n",
    "            plt.annotate(\n",
    "                signicance_str, xy=(offset, this_row['diff'][0]), xytext=(10, -4), fontsize=16,\n",
    "                    textcoords='offset points', ha = 'left', va = 'center',)\n",
    "\n",
    "        offset += 0.5\n",
    "    offset += 0.25\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "plt.xticks(np.arange(0.125,3,1.25), ('0-$f_{end}$ Hz', '4-$f_{end}$ Hz'), rotation=23,\n",
    "          fontsize=14)\n",
    "plt.xlim(-0.5,2.)\n",
    "plt.grid('off', axis='x')\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "    markersize=9, linewidth=0) for h in handles]\n",
    "ax.legend(handles, ('Deep 0-$f_{end}$ Hz', 'Shallow 0-$f_{end}$ Hz',\n",
    "                          'Deep 4-$f_{end}$ Hz', 'Shallow 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1.37,1),\n",
    "         fontsize=14)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "offset = 0\n",
    "for i_var, var_name in enumerate(common_variants):\n",
    "    for freq in [\">0\", \">4\"]:\n",
    "        for net in 'deep5', 'shallow':\n",
    "            markersize = 10\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            this_var = df_mod[(df_mod.variant == var_name) &\n",
    "                             (df_mod.net == net) & \n",
    "                             (df_mod.freq == freq) & \n",
    "                             (df_mod.dataset == 'combined')]\n",
    "            \n",
    "            baseline_test = this_var.test_baseline_subjects[0]\n",
    "            var_test = this_var.test_variant_subjects[0]\n",
    "            diffs = var_test - baseline_test\n",
    "            assert clean_mod_compare, \"Else change logic below with plotting bcic and hgd\"\n",
    "            # could merge\n",
    "            plt.plot(rands[:14] * 0.03 + offset - 0.36,\n",
    "                    diffs[:14], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7) #markersize 8\n",
    "            plt.plot(rands[14:] * 0.03 + offset - 0.36,\n",
    "                    diffs[14:], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7)\n",
    "            plt.errorbar(offset, this_var['diff'][0], color=color,\n",
    "                         yerr=this_var['std'][0], marker=marker,\n",
    "                        markersize=14, label='dummy')\n",
    "            if this_var['wilc'][0] < 0.05:\n",
    "                significance_str = '*'\n",
    "                if this_var['wilc'][0] < 0.01:\n",
    "                    significance_str = '**'\n",
    "                if this_var['wilc'][0] < 0.001:\n",
    "                    significance_str = '***'\n",
    "                plt.annotate(\n",
    "                        significance_str, xy = (offset, this_var['diff'][0]),\n",
    "                    xytext = (5, 15), fontsize=16,\n",
    "                        textcoords = 'offset points', ha = 'center', va = 'top',\n",
    "                color='black')\n",
    "            offset += 0.8\n",
    "        offset += 0.2\n",
    "    offset += 0.4\n",
    "#plt.ylim(-20,10)\n",
    "plt.axhline(y=0, color='grey', linestyle='dashed')\n",
    "\n",
    "plt.xticks(np.arange(1.,21,4), common_variants, rotation=23, fontsize=14)\n",
    "plt.grid('off', axis='x')\n",
    "#plt.xlim(-0.5, plt.xlim()[1]+0.5)\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "plt.xlim(-0.7,plt.xlim()[1]-1)\n",
    "plt.ylim(-80,50)\n",
    "\n",
    "# get handles\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "                 markersize=9, linewidth=0) for h in handles]\n",
    "# use them in the legend\n",
    "ax.legend(handles[:4], ('Deep 0-$f_{end}$ Hz', 'Shallow 0-$f_{end}$ Hz',\n",
    "                        'Deep 4-$f_{end}$ Hz','Shallow 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1,1),\n",
    "         fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "offset = 0\n",
    "for i_var, var_name in enumerate(uncommon_variants):\n",
    "    for freq in [\">0\", \">4\"]:\n",
    "        for net in 'shallow', 'deep5':\n",
    "            if net == 'shallow' and var_name in other_deep_vars:\n",
    "                continue\n",
    "            if net == 'deep5' and var_name in other_shallow_vars:\n",
    "                continue\n",
    "            markersize = 10\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            this_var = df_mod[(df_mod.variant == var_name) &\n",
    "                             (df_mod.net == net) & \n",
    "                             (df_mod.freq == freq) & \n",
    "                             (df_mod.dataset == 'combined')]\n",
    "            \n",
    "            baseline_test = this_var.test_baseline_subjects[0]\n",
    "            var_test = this_var.test_variant_subjects[0]\n",
    "            diffs = var_test - baseline_test\n",
    "            assert clean_mod_compare\n",
    "            plt.plot(rands[:14] * 0.05 + offset - 0.375,\n",
    "                    diffs[:14], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7) #markersize 8\n",
    "            plt.plot(rands[14:] * 0.05 + offset - 0.375,\n",
    "                    diffs[14:], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7)\n",
    "            plt.errorbar(offset, this_var['diff'][0], color=color,\n",
    "                         yerr=this_var['std'][0], marker=marker,\n",
    "                        markersize=14, label='dummy')\n",
    "            if this_var['wilc'][0] < 0.05:\n",
    "                significance_str = '*'\n",
    "                if this_var['wilc'][0] < 0.01:\n",
    "                    significance_str = '**'\n",
    "                if this_var['wilc'][0] < 0.001:\n",
    "                    significance_str = '***'\n",
    "                plt.annotate(\n",
    "                        significance_str, xy = (offset, this_var['diff'][0]),\n",
    "                    xytext = (5, 15), fontsize=16,\n",
    "                        textcoords = 'offset points', ha = 'center', va = 'top',)\n",
    "            offset += 0.6\n",
    "        offset += 0.2\n",
    "    offset += 0.5\n",
    "#plt.ylim(-20,10)\n",
    "plt.axhline(y=0, color='grey', linestyle='dashed')\n",
    "\n",
    "plt.xticks(np.arange(0.4,15,2.1), uncommon_variants, rotation=23,\n",
    "          fontsize=14)\n",
    "plt.grid('off', axis='x')\n",
    "plt.xlim(-0.7, plt.xlim()[1]+0.25)\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "plt.ylim(-40,30)\n",
    "# get handles\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "                 markersize=9, linewidth=0) for h in handles]\n",
    "# use them in the legend\n",
    "ax.legend(handles[:2] + handles[6:8], ('Shallow 0-$f_{end}$ Hz', 'Shallow 4-$f_{end}$ Hz',\n",
    "                                       'Deep 0-$f_{end}$ Hz','Deep 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1.,1),\n",
    "         fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end BLBT to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                fig = plt.figure(figsize=(3.5,3.5))\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared[(all_compared.dataset == dataset) &\n",
    "                                               (all_compared.freq == freq) &\n",
    "                                               (all_compared.train_type == train_type) &\n",
    "                                               (all_compared.name == net) &\n",
    "                                                (all_compared.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "\n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.train_type == train_type) &\n",
    "                                   (all_df.net == net) &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "\n",
    "                plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "\n",
    "                net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                y_label_str = \"{:s} ConvNet\\n{:d}-$f_{{end}}$ Hz Accuracy [%]\".format(net_str, \n",
    "                                                              int(freq[1]))\n",
    "                plt.ylabel(y_label_str, fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With column/row labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        fig, axes = plt.subplots(2,2,figsize=(6.5,6.5), sharex=True, sharey=True)\n",
    "        axes = np.array(axes).flatten()\n",
    "        i_plot = 0\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared[(all_compared.dataset == dataset) &\n",
    "                                               (all_compared.freq == freq) &\n",
    "                                               (all_compared.train_type == train_type) &\n",
    "                                               (all_compared.name == net) &\n",
    "                                                (all_compared.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "                        plt.sca(axes[i_plot])\n",
    "                        i_plot += 1\n",
    "                        \n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.train_type == train_type) &\n",
    "                                   (all_df.net == net) &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "                \n",
    "                \n",
    "                if i_plot > 2:\n",
    "                    plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "                if i_plot <= 2:\n",
    "                    net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                    title_str = \"{:s} ConvNet\".format(net_str)\n",
    "                    plt.title(title_str, fontsize=18, y=1.05)\n",
    "                \n",
    "                if i_plot % 2 == 1:\n",
    "                    y_label_str = u'{:d}—$f_{{end}}$ Hz\\nAccuracy[%]'.format(int(freq[1]))\n",
    "                    #plt.ylabel(y_label_str, fontsize=18)\n",
    "                    plt.text(-10,60,y_label_str, va='center', rotation=90,\n",
    "                            fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for merged net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png' \n",
    "clean = False\n",
    "dataset = 'combined'\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "all_labels = []\n",
    "sig_count_strong = []\n",
    "sig_count_weak = []\n",
    "for freq in ('>0', '>4'):\n",
    "    for net in ('merged',):\n",
    "        for train_type in ('cnt', 'epo',):\n",
    "            this_row = all_compared[(all_compared.dataset == dataset) &\n",
    "                                   (all_compared.freq == freq) &\n",
    "                                   (all_compared.train_type == train_type) &\n",
    "                                   (all_compared.name == net) &\n",
    "                                    (all_compared.clean == clean)]\n",
    "            if net == 'merged' and freq == '0-4': continue\n",
    "            assert len(this_row) == 1\n",
    "            this_row = this_row.iloc[0]\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            elif net == 'merged':\n",
    "                marker = 's'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            else:\n",
    "                assert freq == '0-4'\n",
    "                color = seaborn.color_palette()[3]\n",
    "            \"\"\"if dataset == 'ours':\n",
    "                hsv = rgb_to_hsv(np.array([[color]]))\n",
    "                hsv[0,0,1:] *= 1.1\n",
    "                color = tuple(hsv_to_rgb(hsv)[0,0])\n",
    "            elif dataset == 'bcic':\n",
    "                hsv = rgb_to_hsv(np.array([[color]]))\n",
    "                hsv[0,0,1:] *= 0.85\n",
    "                color = tuple(hsv_to_rgb(hsv)[0,0])\n",
    "            else:\n",
    "                hsv = rgb_to_hsv(np.array([[color]]))\n",
    "                hsv[0,0,1:] *= 1.3\n",
    "                assert np.all(np.logical_or(hsv <= 1, hsv >= 0.))\n",
    "                color = tuple(hsv_to_rgb(hsv)[0,0])\n",
    "            assert np.all(np.logical_or(color <= 1, color >= 0.))\"\"\"\n",
    "\n",
    "            markerfacecolor = 'None'\n",
    "            markersize=10\n",
    "            if train_type == 'epo':\n",
    "                markersize=17\n",
    "\n",
    "            markerfacecolor = 'None'\n",
    "            markeredgecolor = color\n",
    "            if 'cnt' == train_type:\n",
    "                markerfacecolor = color + (0.75,) # some alpha\n",
    "                markeredgecolor = 'black'\n",
    "\n",
    "            test_csp = this_row['test_csp']\n",
    "            test_net = this_row['test_net']\n",
    "\n",
    "\n",
    "            plt.plot(test_csp, test_net, color=color, \n",
    "                     marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                    markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                    markeredgewidth=1)\n",
    "\n",
    "            # add significance star\n",
    "            if this_row['rand'] < 0.05:\n",
    "                if this_row['rand'] < 0.001:\n",
    "                    signicance_str = '***'\n",
    "                    sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                elif this_row['rand'] < 0.01:\n",
    "                    signicance_str = '**'\n",
    "                    sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                else:\n",
    "                    signicance_str = '*'\n",
    "                    sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                plt.annotate(\n",
    "                    signicance_str, xy = (test_csp, test_net), xytext = (10, 0), fontsize=16,\n",
    "                    textcoords = 'offset points', ha = 'left', va = 'center',)\n",
    "\n",
    "\n",
    "min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "\n",
    "\n",
    "plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "\n",
    "plt.ylabel('ConvNet Accuracy [%]', fontsize=18)\n",
    "\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, (\n",
    "                           'Deep 0-4 Hz (cropped)', \n",
    "                           'Deep 0-4 Hz (trial)',\n",
    "                           'Shallow 0-4 Hz (cropped)',\n",
    "                           'Shallow 0-4 Hz (trial)',\n",
    "                           'Deep 0-125 Hz (cropped)', \n",
    "                           'Deep 0-125 Hz (trial)',\n",
    "                           'Shallow 0-125 Hz (cropped)',\n",
    "                           'Shallow 0-125 Hz (trial)',\n",
    "                           'Deep 4-125 Hz (cropped)', \n",
    "                           'Deep 4-125 Hz (trial)',\n",
    "                           'Shallow 4-125 Hz (cropped)',\n",
    "                           'Shallow 4-125 Hz (trial)',),\n",
    "          bbox_to_anchor=(1.75,1),fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.annotate(u\"$N_{{ConvNet>FBCSP}}$ = {:d}\".format(np.sum(np.array(sig_count_strong) == 1)\n",
    "                                            + np.sum(np.array(sig_count_weak) == 1)),xy=(56,92),\n",
    "            fontsize=22)\n",
    "plt.annotate(u\"$N_{{ConvNet<FBCSP}}$ = {:d}\".format(np.sum(np.array(sig_count_strong) == -1)\n",
    "                                            + np.sum(np.array(sig_count_weak) == -1)),xy=(93,57),\n",
    "            fontsize=22, ha='right')\n",
    "\n",
    "\n",
    "# We change the fontsize of minor ticks label \n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "plt.gca().add_artist(circle)\n",
    "plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-35,15), textcoords='offset points', va='center',\n",
    "            ha='right', fontsize=18, color=(0.3,)*3)\n",
    "\n",
    "ax = plt.gca()\n",
    "clean_str = 'Restricted subjects' if clean else 'All subjects'\n",
    "plt.title(\"Complete dataset, $N$=29\", fontsize=16, y=1.02)\n",
    "#title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "#plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "\n",
    "# add small line for significance star\n",
    "this_row = all_compared[(all_compared.dataset == 'combined') &\n",
    "                       (all_compared.freq == '>4') &\n",
    "                       (all_compared.train_type == 'cnt') &\n",
    "                       (all_compared.name == 'shallow') &\n",
    "                        (all_compared.clean == False)]\n",
    "this_row = this_row.iloc[0]\n",
    "plt.plot([this_row.test_csp,this_row.test_csp+1.5],[this_row.test_net-0.2,this_row.test_net+0.2], color='black',\n",
    "         linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### significance tests hybrid vs deep and retests of main result with different significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared[(all_compared.dataset == 'combined') & \n",
    "            (all_compared.clean == True) &\n",
    "            (all_compared.train_type =='cnt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_above_0 = all_df[(all_df.freq == '>0') &\n",
    "                           (all_df.train_type == 'cnt')& \n",
    "                           (all_df.net == 'deep5') &\n",
    "                           (all_df.clean == True)]\n",
    "deep_above_4 = all_df[(all_df.freq == '>4') &\n",
    "                           (all_df.train_type == 'cnt')& \n",
    "                           (all_df.net == 'deep5') &\n",
    "                           (all_df.clean == True)]\n",
    "csp_acc_above_0 = all_df[(all_df.freq == '>0') &\n",
    "                           (all_df.train_type == 'epo')& \n",
    "                           (all_df.net == 'csp') &\n",
    "                           (all_df.clean == True)]\n",
    "csp_acc_above_4 = all_df[(all_df.freq == '>4') &\n",
    "                           (all_df.train_type == 'epo')& \n",
    "                           (all_df.net == 'csp') &\n",
    "                           (all_df.clean == True)]\n",
    "merged_above_0 = all_df[(all_df.freq == '>0') &\n",
    "                           (all_df.train_type == 'cnt')& \n",
    "                           (all_df.net == 'merged') &\n",
    "                           (all_df.clean == True)]\n",
    "merged_above_4 = all_df[(all_df.freq == '>4') &\n",
    "                           (all_df.train_type == 'cnt')& \n",
    "                           (all_df.net == 'merged') &\n",
    "                           (all_df.clean == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_vs_csp_0 = csp_acc_above_0.merge(deep_above_0, on=('dataset_filename', 'freq'))\n",
    "assert len(deep_vs_csp_0) == 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_vs_csp_4 = csp_acc_above_4.merge(deep_above_4, on=('dataset_filename', 'freq'))\n",
    "assert len(deep_vs_csp_4) == 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wilcoxon_signed_rank(deep_vs_csp_0.test_x, deep_vs_csp_0.test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.wilcoxon(deep_vs_csp_0.test_x, deep_vs_csp_0.test_y, zero_method='zsplit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(deep_above_0, merged_above_0, '','','', with_csp_acc=True,\n",
    "               max_n_p_vals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(deep_above_4, merged_above_4, '','','', with_csp_acc=True,\n",
    "               max_n_p_vals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without ELU/Bnorm/Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df_past = pd.DataFrame()\n",
    "for dataset in ('bcic', 'ours'):\n",
    "    for net in 'shallow', 'deep5':\n",
    "        for training in 'epo', 'cnt':\n",
    "            for band in ['>0', '>4']:\n",
    "                for clean in (True, False):\n",
    "                    if dataset == 'bcic':\n",
    "                        dfc = df_csp_bcic\n",
    "                    else:\n",
    "                        assert dataset == 'ours'\n",
    "                        dfc = df_csp_ours\n",
    "                    if dataset == 'bcic' and net == 'shallow' and training == 'cnt':\n",
    "                        dfn = df_shallow_cnt_bcic\n",
    "                    elif dataset == 'bcic' and net == 'shallow' and training == 'epo':\n",
    "                        dfn = df_shallow_epo_bcic\n",
    "                    elif dataset == 'bcic' and net == 'deep5' and training == 'cnt':\n",
    "                        dfn = df_deep_cnt_bcic\n",
    "                    elif dataset == 'bcic' and net == 'deep5' and training == 'epo':\n",
    "                        dfn = df_deep_epo_bcic\n",
    "                    elif dataset == 'ours' and net == 'shallow' and training == 'cnt':\n",
    "                        dfn = df_shallow_cnt_ours\n",
    "                    elif dataset == 'ours' and net == 'shallow' and training == 'epo':\n",
    "                        dfn = df_shallow_epo_ours\n",
    "                    elif dataset == 'ours' and net == 'deep5' and training == 'cnt':\n",
    "                        dfn = df_deep_cnt_ours\n",
    "                    elif dataset == 'ours' and net == 'deep5' and training == 'epo':\n",
    "                        dfn = df_deep_epo_ours\n",
    "                    else:\n",
    "                        raise ValueError(\"Unknown combination\")\n",
    "                    if clean:\n",
    "                        dfn = clean_datasets(dfn)\n",
    "                        dfc = clean_datasets(dfc)\n",
    "                    \n",
    "                    dfn = past(dfn)\n",
    "                        \n",
    "                    if band == '>0':\n",
    "                        this_dfn = above_0(dfn)\n",
    "                        this_dfc = csp_above_0(dfc)\n",
    "                    elif band == '>4':\n",
    "                        this_dfn = above_4(dfn)\n",
    "                        this_dfc = csp_above_4(dfc)\n",
    "                    elif band == '0-4':\n",
    "                        this_dfn = from_0_to_4(dfn)\n",
    "                        this_dfc = csp_0_to_4(dfc)\n",
    "                        \n",
    "                    if training == 'cnt':\n",
    "                        this_dfn = tied_loss(this_dfn)\n",
    "                        \n",
    "                    this_dfc = main_comp_csp(this_dfc)\n",
    "                    \n",
    "                    this_dfc = this_dfc[this_dfc.trial_start == 500]\n",
    "                    if training == 'epo':\n",
    "                        this_dfn = this_dfn[this_dfn.trial_start == -500]\n",
    "                    else:\n",
    "                        assert training == 'cnt'\n",
    "                        this_dfn = this_dfn[this_dfn.trial_start == 1500]\n",
    "                        \n",
    "                    this_dfc = restrict_or_missing_col(this_dfc, max_abs_threshold=800)\n",
    "                    \n",
    "                    if dataset == 'bcic' and net == 'deep5' and (\n",
    "                        training == 'epo' or (band == '>0' or band == '>4')):\n",
    "                        this_dfn = this_dfn[this_dfn.layers == 'deep_5']\n",
    "                    if training == 'epo':\n",
    "                        this_dfn = this_dfn[this_dfn.max_increasing_epochs == 160]\n",
    "                    else:\n",
    "                        assert training == 'cnt'\n",
    "                        this_dfn = this_dfn[this_dfn.max_increasing_epochs == 80]\n",
    "\n",
    "                    if dataset == 'bcic':\n",
    "                        assert len(this_dfc) == 9, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                        assert len(this_dfn) == 9, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                    elif dataset == 'ours' and clean:\n",
    "                        assert len(this_dfc) == 14, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                        assert len(this_dfn) == 14, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                    elif dataset == 'ours' and (not clean):\n",
    "                        assert len(this_dfc) == 20, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfc), str((dataset, net, training, band, clean)))\n",
    "                        assert len(this_dfn) == 20, \"wrong length: {:d} ({:s})\".format(\n",
    "                            len(this_dfn), str((dataset, net, training, band, clean)))\n",
    "                    else:\n",
    "                        raise ValueError(\"Unknown combination\")\n",
    "\n",
    "                \n",
    "                    this_dfn = remove_columns_with_same_value(this_dfn)\n",
    "                    this_dfn['clean'] = clean\n",
    "                    this_dfn['net'] = net\n",
    "                    this_dfn['train_type'] = training\n",
    "                    this_dfn['freq'] = band\n",
    "                    this_dfn['dataset'] = dataset\n",
    "\n",
    "                    all_df_past = all_df_past.append(this_dfn)\n",
    "                    # no need to add csp... comparison csp stays same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(all_df_past) == 8 * 29 +  8* 23 # no csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_compared_past = pd.DataFrame()\n",
    "param_keys = ['dataset', 'freq', 'net',  'train_type', 'clean']\n",
    "all_groups = all_df_past.groupby(param_keys)\n",
    "\n",
    "for name, group in all_groups:\n",
    "    assert len(group['freq'].unique()) == 1\n",
    "    freq = group['freq'].iloc[0]\n",
    "    assert len(group['dataset'].unique()) == 1\n",
    "    dataset = group['dataset'].iloc[0]\n",
    "    assert len(group['net'].unique()) == 1\n",
    "    net = group['net'].iloc[0]\n",
    "    assert len(group['clean'].unique()) == 1\n",
    "    clean = group['clean'].iloc[0]\n",
    "    assert len(group['train_type'].unique()) == 1\n",
    "    train_type = group['train_type'].iloc[0]\n",
    "    if net == 'csp': continue\n",
    "    log.info(\"{:s} {:s} {:s} {:s} (clean: {:s})\".format(dataset,\n",
    "                                                        freq,net, train_type, str(clean)))\n",
    "    csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                (all_df.dataset == dataset) &\n",
    "                (all_df.clean == clean)]\n",
    "    df_compare = compare_net_csp(group, csp, net, freq, dataset, with_csp_acc=True, with_std=True,\n",
    "                                with_std_error=True)   \n",
    "    df_compare['clean'] = clean\n",
    "    df_compare['train_type'] = train_type\n",
    "    all_compared_past = all_compared_past.append(df_compare)\n",
    "\n",
    "\n",
    "param_keys = ['freq', 'net',  'train_type', 'clean']\n",
    "all_groups = all_df_past.groupby(param_keys)\n",
    "\n",
    "for name, group in all_groups:\n",
    "    assert len(group['freq'].unique()) == 1\n",
    "    freq = group['freq'].iloc[0]\n",
    "    assert len(group['net'].unique()) == 1\n",
    "    net = group['net'].iloc[0]\n",
    "    assert len(group['clean'].unique()) == 1\n",
    "    clean = group['clean'].iloc[0]\n",
    "    assert len(group['train_type'].unique()) == 1\n",
    "    train_type = group['train_type'].iloc[0]\n",
    "    if net == 'csp': continue\n",
    "    log.info(\"combined: {:s} {:s} {:s} (clean: {:s})\".format(freq,net, train_type, str(clean)))\n",
    "    csp = all_df[(all_df.net == 'csp') & (all_df.freq == freq) &\n",
    "                (all_df.clean == clean)]\n",
    "    assert (len(csp) == 29 and not clean) or (len(csp) == 23 and clean)\n",
    "    df_compare = compare_net_csp(group, csp, net, freq, 'combined', with_csp_acc=True, with_std=True,\n",
    "                                with_std_error=True)\n",
    "    df_compare['clean'] = clean\n",
    "    df_compare['train_type'] = train_type\n",
    "    all_compared_past = all_compared_past.append(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png' \n",
    "\n",
    "all_labels = []\n",
    "for clean in (True,) : #False\n",
    "    plt.figure(figsize=(12,0.1))\n",
    "    plt.title(\"Clean: \" + str(clean), fontsize=16)\n",
    "    plt.axis('off')\n",
    "    for stat_test in ('wilc', ):#'sign','rand',\n",
    "        plt.figure(figsize=(12,0.1))\n",
    "        plt.title(stat_test)\n",
    "        plt.axis('off')\n",
    "        fig, axes = plt.subplots(2,2,figsize=(6.5,6.5), sharex=True, sharey=True)\n",
    "        axes = np.array(axes).flatten()\n",
    "        i_plot = 0\n",
    "        for freq in ('>0', '>4'):\n",
    "            for net in ('deep5', 'shallow'):\n",
    "                for train_type in ('cnt',):\n",
    "                    for dataset in ('combined',):#, 'ours', 'bcic'\n",
    "                        this_row = all_compared_past[(all_compared_past.dataset == dataset) &\n",
    "                                               (all_compared_past.freq == freq) &\n",
    "                                               (all_compared_past.train_type == train_type) &\n",
    "                                               (all_compared_past.name == net) &\n",
    "                                                (all_compared_past.clean == clean)]\n",
    "                        if net == 'merged' and freq == '0-4': continue\n",
    "                        assert len(this_row) == 1\n",
    "                        this_row = this_row.iloc[0]\n",
    "                        if net == 'deep5':\n",
    "                            marker = 'o'\n",
    "                        elif net == 'merged':\n",
    "                            marker = 's'\n",
    "                        else:\n",
    "                            assert net == 'shallow'\n",
    "                            marker = '^'\n",
    "                        if dataset == 'bcic':\n",
    "                            marker = '^'\n",
    "                        elif dataset == 'ours':\n",
    "                            marker = 'o'\n",
    "                        if '>0' == freq:\n",
    "                            color = seaborn.color_palette()[0]\n",
    "                        elif '>4' == freq:\n",
    "                            color = seaborn.color_palette()[1]\n",
    "                        else:\n",
    "                            assert freq == '0-4'\n",
    "                            color = seaborn.color_palette()[3]\n",
    "                        color=(0.5,0.5,0.5)\n",
    "                        markerfacecolor = 'None'\n",
    "                        markersize=10\n",
    "                        if train_type == 'epo':\n",
    "                            markersize=17\n",
    "\n",
    "                        markerfacecolor = 'None'\n",
    "                        markeredgecolor = color\n",
    "                        if 'cnt' == train_type:\n",
    "                            markerfacecolor = color + (0.75,) # some alpha\n",
    "                            markeredgecolor = 'black'\n",
    "\n",
    "                        test_csp = this_row['test_csp']\n",
    "                        test_net = this_row['test_net']\n",
    "                        plt.sca(axes[i_plot])\n",
    "                        i_plot += 1\n",
    "                        \n",
    "                        if dataset == 'combined':\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker='s', linestyle='None', markersize=markersize+2, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "                        else:\n",
    "                            plt.plot(test_csp, test_net, color=color, \n",
    "                                 marker=marker, linestyle='None', markersize=markersize, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1)\n",
    "\n",
    "                        # add significance star\n",
    "                        if this_row[stat_test] < 0.05:\n",
    "                            if this_row[stat_test] < 0.001:\n",
    "                                signicance_str = '***'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "                            elif this_row[stat_test] < 0.01:\n",
    "                                signicance_str = '**'\n",
    "                                sig_count_strong.append(int(np.sign(test_net - test_csp)))\n",
    "\n",
    "                            else:\n",
    "                                signicance_str = '*'\n",
    "                                sig_count_weak.append(int(np.sign(test_net - test_csp)))\n",
    "                            if test_csp < test_net:\n",
    "                                xytext = (-6, -2)\n",
    "                            else:\n",
    "                                xytext = (3,-12)\n",
    "                            plt.annotate(\n",
    "                                signicance_str, xy = (test_csp, test_net), xytext = xytext, fontsize=18,\n",
    "                                textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                                color='black')\n",
    "                        \"\"\"\n",
    "                        dataset_str = dataset.upper()[:4].replace(\"OURS\", \"HGD\")\n",
    "\n",
    "                        xytext=(-25,10)\n",
    "                        if dataset == 'combined':\n",
    "                            xytext = (-25,5)\n",
    "                        plt.annotate(dataset_str,xy=(test_csp, test_net), xytext=xytext,\n",
    "                                     textcoords='offset points', va='center',\n",
    "                                ha='right', fontsize=14, color=(0.3,)*3,\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=(0.,)*3))\n",
    "                        \"\"\"\n",
    "                        if dataset == 'combined':\n",
    "                            df_net = all_df_past[\n",
    "                                   (all_df_past.freq == freq) &\n",
    "                                   (all_df_past.train_type == train_type) &\n",
    "                                   (all_df_past.net == net) &\n",
    "                                    (all_df_past.clean == clean)]\n",
    "\n",
    "                            df_csp = all_df[\n",
    "                                   (all_df.freq == freq) &\n",
    "                                   (all_df.net == 'csp') &\n",
    "                                    (all_df.clean == clean)]\n",
    "\n",
    "                            df_merged = df_net.merge(df_csp, on='dataset_filename', suffixes=('_net','_csp'))\n",
    "                            test_per_sub_csp_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_csp\n",
    "                            test_per_sub_csp_ours = df_merged[df_merged.dataset_net == 'ours'].test_csp\n",
    "                            test_per_sub_net_bcic = df_merged[df_merged.dataset_net == 'bcic'].test_net\n",
    "                            test_per_sub_net_ours = df_merged[df_merged.dataset_net == 'ours'].test_net\n",
    "                            plt.plot(test_per_sub_csp_bcic, test_per_sub_net_bcic, color=color, \n",
    "                                 marker='^', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            plt.plot(test_per_sub_csp_ours, test_per_sub_net_ours, color=color, \n",
    "                                 marker='o', linestyle='None', markersize=3, label='dummy',\n",
    "                                markerfacecolor=markerfacecolor, markeredgecolor=markeredgecolor,\n",
    "                                markeredgewidth=1, alpha=0.4)\n",
    "                            test_per_sub_csp = np.concatenate([test_per_sub_csp_bcic, test_per_sub_csp_ours])\n",
    "                            test_per_sub_net = np.concatenate([test_per_sub_net_bcic, test_per_sub_net_ours])\n",
    "                            correlation = np.corrcoef(test_per_sub_csp, test_per_sub_net)[0,1]\n",
    "                            n_above = np.sum(test_per_sub_net > test_per_sub_csp)\n",
    "                            n_below = np.sum(test_per_sub_net < test_per_sub_csp)\n",
    "\n",
    "\n",
    "                #min_x_y = min(plt.xlim()[0], plt.ylim()[0])\n",
    "                #max_x_y = max(plt.xlim()[1], plt.ylim()[1])\n",
    "                #plt.plot([min_x_y-5,max_x_y+5], [min_x_y-5,max_x_y+5], color='black', label='', linestyle='--', lw=1)\n",
    "                plt.plot([20,100], [20,100], color='black', label='', linestyle='--', lw=1)\n",
    "                \n",
    "                \n",
    "                if i_plot > 2:\n",
    "                    plt.xlabel('FBCSP Accuracy [%]', fontsize=18)\n",
    "                if i_plot <= 2:\n",
    "                    net_str = net.capitalize().replace(\"5\", \"\")\n",
    "                    title_str = \"{:s} ConvNet\".format(net_str)\n",
    "                    plt.title(title_str, fontsize=18, y=1.05)\n",
    "                \n",
    "                if i_plot % 2 == 1:\n",
    "                    y_label_str = u'{:d}—$f_{{end}}$ Hz\\nAccuracy[%]'.format(int(freq[1]))\n",
    "                    #plt.ylabel(y_label_str, fontsize=18)\n",
    "                    plt.text(-10,60,y_label_str, va='center', rotation=90,\n",
    "                            fontsize=18)\n",
    "\n",
    "                ax = plt.gca()\n",
    "\n",
    "                plt.tight_layout()\n",
    "                #plt.annotate(u\"c: {:.2f}\".format(correlation),xy=(97,24),\n",
    "                #            fontsize=16, ha='right', va='center')\n",
    "                #plt.annotate(u\"Above: {:d}\".format(n_above),xy=(23,93),\n",
    "                #            fontsize=16, ha='left')\n",
    "\n",
    "                #plt.annotate(u\"Below: {:d}\".format(n_below),xy=(97,33),\n",
    "                #            fontsize=16, ha='right')\n",
    "\n",
    "\n",
    "                # We change the fontsize of minor ticks label \n",
    "                plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "                \"\"\"circle = plt.Circle((84,84), 4, facecolor='None', linestyle='dotted', linewidth=1)\n",
    "                plt.gca().add_artist(circle)\n",
    "                plt.annotate(u\"Main\\ncomparison\",xy=(84,84), xytext=(-25,15), textcoords='offset points', va='center',\n",
    "                            ha='right', fontsize=16, color=(0.3,)*3)\"\"\"\n",
    "\n",
    "                ax = plt.gca()\n",
    "                title_str = \"{:s} {:d}-$f_{{end}}$ Hz\".format(net.capitalize().replace(\"5\", \"\"), \n",
    "                                                              int(freq[1]))\n",
    "                #plt.title(title_str, fontsize=16, y=1.02)\n",
    "                #title_str = dataset.capitalize().replace(\"Ours\", \"HGD\") + \" \" + clean_str\n",
    "                #plt.title('{:s}'.format(title_str), fontsize=16)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.figure(figsize=(0.1,0.1))\n",
    "        ax = plt.gca()\n",
    "        ax.legend(np.array(handles), [\"Combined Mean\", \"BCI Competition\", \"High Gamma Dataset\", ], \n",
    "                  bbox_to_anchor=(2.,1.05), fontsize=14, ncol=3)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial vs Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_trial_sample = True\n",
    "    \n",
    "df_cnt = all_compared[(all_compared.train_type == 'cnt') &\n",
    "                     (all_compared.clean == clean_trial_sample)]\n",
    "\n",
    "df_cnt_epo = pd.DataFrame()\n",
    "for i_row in xrange(len(df_cnt)):\n",
    "    this_row = df_cnt.iloc[i_row,:]\n",
    "    \n",
    "    if this_row['dataset'] in ('bcic', 'ours'):\n",
    "        this_cnt = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq'])& \n",
    "                         (all_df.dataset == this_row['dataset']) &\n",
    "                         (all_df.train_type == 'cnt') &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "    else:\n",
    "        assert this_row['dataset'] == 'combined'\n",
    "        this_cnt_1 = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq'])& \n",
    "                         (all_df.dataset == 'bcic') &\n",
    "                         (all_df.train_type == 'cnt') &\n",
    "                         (all_df.clean == clean_trial_sample) &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "        this_cnt_2 = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq'])& \n",
    "                         (all_df.dataset == 'ours') &\n",
    "                         (all_df.train_type == 'cnt') &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "        this_cnt = pd.concat((this_cnt_1, this_cnt_2))\n",
    "\n",
    "    if this_row['dataset'] in ('bcic', 'ours'):\n",
    "        this_epo = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq'])& \n",
    "                         (all_df.dataset == this_row['dataset']) &\n",
    "                         (all_df.train_type == 'epo') &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "    else:\n",
    "        assert this_row['dataset'] == 'combined'\n",
    "        this_epo_1 = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq']) & \n",
    "                         (all_df.dataset == 'bcic') &\n",
    "                         (all_df.train_type == 'epo') &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "        this_epo_2 = all_df[(all_df.net == this_row['name']) & \n",
    "                         (all_df.freq == this_row['freq']) & \n",
    "                         (all_df.dataset == 'ours') &\n",
    "                         (all_df.train_type == 'epo') &\n",
    "                         (all_df.clean == clean_trial_sample)]\n",
    "        this_epo = pd.concat((this_epo_1, this_epo_2))\n",
    "    df_merged = this_epo.merge(this_cnt, on='dataset_filename', suffixes=('_epo','_cnt'))\n",
    "    # this is only for latter scatterplot\n",
    "    df_merged = df_merged.sort_values(by='dataset_filename')\n",
    "    \n",
    "    cnt_test = np.array(df_merged['test_cnt'])\n",
    "    epo_test = np.array(df_merged['test_epo'])\n",
    "        \n",
    "    this_df = pd.DataFrame()\n",
    "    this_df['dataset'] = [this_row['dataset']]\n",
    "    this_df['net'] = [this_row['name'].replace('cnt ', '')]\n",
    "    this_df['freq'] = [this_row['freq']]\n",
    "    this_df['test'] = [np.mean(epo_test)]\n",
    "    this_df['diff'] = [np.mean(cnt_test - epo_test)]\n",
    "    this_df['std'] = [np.std(cnt_test - epo_test)]\n",
    "    this_df['stderr'] = [np.std(cnt_test - epo_test) / np.sqrt(len(cnt_test))]\n",
    "    this_df['test_epo_subjects'] = [epo_test]\n",
    "    this_df['test_cnt_subjects'] = [cnt_test]\n",
    "    log.info(\"{:s} {:s} {:s}\".format(this_row['dataset'],\n",
    "        this_row['freq'], this_row['name']))\n",
    "    add_p_vals_to_df_row(this_df, cnt_test, epo_test)\n",
    "    \n",
    "    df_cnt_epo = pd.concat((df_cnt_epo, this_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "rng = RandomState(39884934)\n",
    "plt.figure(figsize=(12,4))\n",
    "rands = rng.randn(23) #rng.randn(len(diffs))\n",
    "offset = 0\n",
    "for freq in ('>0', '>4'):\n",
    "    for net in ('deep5', 'shallow'):\n",
    "        this_row = df_cnt_epo[(df_cnt_epo.dataset == 'combined') &\n",
    "                             (df_cnt_epo.freq == freq) &\n",
    "                             (df_cnt_epo.net == net)]\n",
    "        label = 'dummy'\n",
    "        if net == 'deep5':\n",
    "            marker = 'o'\n",
    "        else:\n",
    "            assert net == 'shallow'\n",
    "            marker = '^'\n",
    "        if '0-4' == freq:\n",
    "            color = seaborn.color_palette()[3]\n",
    "        elif '>0' == freq:\n",
    "            color = seaborn.color_palette()[0]\n",
    "        elif '>4' == freq:\n",
    "            color = seaborn.color_palette()[1]\n",
    "        \n",
    "\n",
    "\n",
    "        cnt_test = this_row['test_cnt_subjects'][0]\n",
    "        epo_test = this_row['test_epo_subjects'][0]\n",
    "        diffs = cnt_test - epo_test\n",
    "        # try plotting ours and bcic with different marker sizes, quite hacky(first 14 shouldbe ours)\n",
    "        # not doing anymore\n",
    "        assert clean_trial_sample\n",
    "        plt.plot(rands[:14] * 0.05 + offset - 0.2,\n",
    "                diffs[:14], color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                markersize=8) #markersize 8\n",
    "        plt.plot(rands[14:] * 0.05 + offset - 0.2,\n",
    "                diffs[14:], color=color, marker=marker, alpha=0.5, linestyle='None',\n",
    "                markersize=8)\n",
    "        plt.errorbar(offset, this_row['diff'][0], color=color,\n",
    "                     yerr=this_row['std'][0], marker=marker,\n",
    "                    markersize=14, label=label)\n",
    "\n",
    "        if this_row['wilc'][0] < 0.05:\n",
    "            if this_row['wilc'][0] < 0.001:\n",
    "                signicance_str = '***'\n",
    "            elif this_row['wilc'][0] < 0.01:\n",
    "                signicance_str = '**'\n",
    "            else:\n",
    "                signicance_str = '*'\n",
    "            plt.annotate(\n",
    "                signicance_str, xy=(offset, this_row['diff'][0]), xytext=(10, -4), fontsize=16,\n",
    "                    textcoords='offset points', ha = 'left', va = 'center',)\n",
    "\n",
    "        offset += 0.5\n",
    "    offset += 0.25\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "plt.xticks(np.arange(0.125,3,1.25), ('0-$f_{end}$ Hz', '4-$f_{end}$ Hz'), rotation=23,\n",
    "          fontsize=14)\n",
    "plt.xlim(-0.5,2.)\n",
    "plt.grid('off', axis='x')\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "    markersize=9, linewidth=0) for h in handles]\n",
    "ax.legend(handles, ('Deep 0-$f_{end}$ Hz', 'Shallow 0-$f_{end}$ Hz',\n",
    "                          'Deep 4-$f_{end}$ Hz', 'Shallow 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1.25,1),\n",
    "         fontsize=14)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rands[:14] * 0.05 + offset - 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rands[14:] * 0.05 + offset - 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_mod_compare = True\n",
    "df_mod = pd.DataFrame()\n",
    "shallow_variants = [\n",
    "                   ('No Dropout', lambda df: no_drop(yes_bnorm(df))),\n",
    "                   ('No Batch Norm', lambda df: yes_drop(no_bnorm(df))),\n",
    "                   ('No Dropout No Batch Norm', lambda df: no_drop(no_bnorm(df))),\n",
    "                   ('No Split 1st Layer', no_split_first_layer),\n",
    "                   ('No Tied Loss', no_tied_loss),\n",
    "                   ('Sqrt instead of log', square_mean_sqrt),\n",
    "                   ('Elu Max', elu_max_shallow),\n",
    "                   ('Elu Mean', elu_mean_shallow),]\n",
    "\n",
    "deep_variants = [\n",
    "                   ('No Dropout', lambda df: tied_loss(no_drop(yes_bnorm(df)))),\n",
    "                   ('No Batch Norm', lambda df: tied_loss(split_first_layer(yes_drop(no_bnorm(df))))),\n",
    "                   ('No Dropout No Batch Norm', lambda df: tied_loss(\n",
    "                        single_time_convs(elu_nonlins(no_drop(no_bnorm(df)))))),\n",
    "                   ('No Split 1st Layer', no_split_first_layer),\n",
    "                   ('No Tied Loss', lambda df: no_tied_loss(\n",
    "                        single_time_convs(yes_drop(yes_bnorm(elu_nonlins(df)))))),\n",
    "                   ('ReLU', lambda df: relu_nonlins(yes_bnorm(df))),\n",
    "                   ('Log(Mean(Square)) first', square_mean_first),\n",
    "                   ('Log(Max(Square)) first', square_max_first),\n",
    "                   ('6x1+6x1 convs', double_time_convs),]\n",
    "\n",
    "for dataset in 'bcic', 'ours', 'combined':\n",
    "    for net in 'shallow', 'deep5':\n",
    "        if net == 'shallow':\n",
    "            variants = shallow_variants\n",
    "        else:\n",
    "            assert net == 'deep5'\n",
    "            variants = deep_variants\n",
    "        if dataset == 'bcic' and net == 'shallow':\n",
    "            df_compare = df_shallow_cnt_bcic\n",
    "        elif dataset == 'bcic' and net == 'deep5':\n",
    "            df_compare = df_deep_cnt_bcic\n",
    "        elif dataset == 'ours' and net == 'shallow':\n",
    "            df_compare = df_shallow_cnt_ours\n",
    "        elif dataset == 'ours' and net == 'deep5':\n",
    "            df_compare = df_deep_cnt_ours\n",
    "        elif dataset == 'combined' and net == 'shallow':\n",
    "            df_compare = (df_shallow_cnt_bcic, df_shallow_cnt_ours)\n",
    "        elif dataset == 'combined' and net == 'deep5':\n",
    "            df_compare = (df_deep_cnt_bcic, df_deep_cnt_ours)\n",
    "        else:\n",
    "            raise ValueError(\"unknown combination\")\n",
    "            \n",
    "        if clean_mod_compare:\n",
    "            if dataset != 'combined':\n",
    "                df_compare = clean_datasets(df_compare)\n",
    "            else:\n",
    "                assert dataset == 'combined'\n",
    "                df_compare = [clean_datasets(df_set) for df_set in df_compare]\n",
    "        if dataset != 'combined':\n",
    "            df_compare = df_compare[df_compare.max_increasing_epochs == 80]\n",
    "        else:\n",
    "            assert dataset == 'combined'\n",
    "            df_compare = [df_set[df_set.max_increasing_epochs == 80] for df_set in df_compare]\n",
    "            \n",
    "        for freq in '>0', '>4':\n",
    "            if dataset in ('bcic', 'ours'):\n",
    "                df_baseline = all_df[(all_df.net == net)&\n",
    "                                    (all_df.freq == freq) &\n",
    "                                    (all_df.dataset == dataset) &\n",
    "                                    (all_df.train_type == 'cnt') &\n",
    "                                    (all_df.clean == clean_mod_compare)]\n",
    "            else:\n",
    "                df_baseline =  all_df[(all_df.net == net)&\n",
    "                                    (all_df.freq == freq) &\n",
    "                                    (all_df.train_type == 'cnt') &\n",
    "                                    (all_df.clean == clean_mod_compare)]\n",
    "                \n",
    "            # new, if needed\n",
    "            #df_compare = restrict_or_missing_col(df_compare, max_abs_threshold=800)\n",
    "            for var_name, var_func in variants:\n",
    "                if freq == '>0' and dataset in ('bcic', 'ours'):\n",
    "                    df_var = var_func(above_0(df_compare))\n",
    "                elif dataset in ('bcic', 'ours'):\n",
    "                    assert freq == '>4'\n",
    "                    df_var = var_func(above_4(df_compare))\n",
    "                elif freq == '>0' and dataset == 'combined':\n",
    "                    df_var_1 = var_func(above_0(df_compare[0]))\n",
    "                    df_var_2 = var_func(above_0(df_compare[1]))\n",
    "                    df_var = pd.concat((df_var_1, df_var_2))\n",
    "                elif freq == '>4' and dataset == 'combined':\n",
    "                    df_var_1 = var_func(above_4(df_compare[0]))\n",
    "                    df_var_2 = var_func(above_4(df_compare[1]))\n",
    "                    df_var = pd.concat((df_var_1, df_var_2))\n",
    "                if var_name != 'No Tied Loss':\n",
    "                    df_var = tied_loss(df_var)\n",
    "                if dataset == 'bcic':\n",
    "                    assert len(df_var) == 9\n",
    "                elif dataset == 'ours':\n",
    "                    assert len(df_var) == 20 or (len(df_var) == 14 and clean_mod_compare)\n",
    "                else:\n",
    "                    assert dataset == 'combined'\n",
    "                    assert len(df_var) == 29 or (len(df_var) == 23 and clean_mod_compare)\n",
    "                assert len(df_var) == len(df_baseline), (\n",
    "                    \"Expect length of variant {:d} to be same as length of baseline {:d}\".format(\n",
    "                    len(df_var), len(df_baseline)))\n",
    "                df_merged = df_baseline.merge(df_var, on='dataset_filename', suffixes=('_base','_var'))\n",
    "                # not really necessary to sort, just to make sure \n",
    "                df_merged = df_merged.sort_values(by='dataset_filename')\n",
    "                test_baseline = np.array(df_merged.test_base)\n",
    "                test_variant = np.array(df_merged.test_var)\n",
    "                this_df_mod = pd.DataFrame()\n",
    "                this_df_mod['dataset'] = [dataset]\n",
    "                this_df_mod['net'] = [net]\n",
    "                this_df_mod['freq'] = [freq]\n",
    "                this_df_mod['variant'] = [var_name]\n",
    "                this_df_mod['test'] = [np.mean(df_merged.test_var)]\n",
    "                this_df_mod['diff'] = [np.mean(df_merged.test_var - df_merged.test_base)]\n",
    "                this_df_mod['std'] = [np.std(df_merged.test_var - df_merged.test_base)]\n",
    "                this_df_mod['stderr'] = [np.std(df_merged.test_var - df_merged.test_base) / \n",
    "                                         np.sqrt(len(df_merged))]\n",
    "                this_df_mod['test_baseline_subjects'] = [test_baseline]\n",
    "                this_df_mod['test_variant_subjects'] = [test_variant]\n",
    "                \n",
    "                add_p_vals_to_df_row(this_df_mod, test_variant, \n",
    "                                     test_baseline, n_diffs_for_large=2**17)\n",
    "                df_mod = pd.concat((df_mod, this_df_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_variants = np.intersect1d(zip(*deep_variants)[0], zip(*shallow_variants)[0])\n",
    "\n",
    "other_shallow_vars = np.setdiff1d(zip(*shallow_variants)[0], zip(*deep_variants)[0])[::-1]\n",
    "other_deep_vars = np.setdiff1d(zip(*deep_variants)[0], zip(*shallow_variants)[0])[::-1]\n",
    "all_variants = np.concatenate((common_variants, other_shallow_vars,other_deep_vars))\n",
    "\n",
    "uncommon_variants = np.concatenate((other_shallow_vars, other_deep_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "offset = 0\n",
    "for i_var, var_name in enumerate(common_variants):\n",
    "    for freq in [\">0\", \">4\"]:\n",
    "        for net in 'deep5', 'shallow':\n",
    "            markersize = 10\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            this_var = df_mod[(df_mod.variant == var_name) &\n",
    "                             (df_mod.net == net) & \n",
    "                             (df_mod.freq == freq) & \n",
    "                             (df_mod.dataset == 'combined')]\n",
    "            \n",
    "            baseline_test = this_var.test_baseline_subjects[0]\n",
    "            var_test = this_var.test_variant_subjects[0]\n",
    "            diffs = var_test - baseline_test\n",
    "            assert clean_mod_compare, \"Else change logic below with plotting bcic and hgd\"\n",
    "            # could merge\n",
    "            plt.plot(rands[:14] * 0.03 + offset - 0.36,\n",
    "                    diffs[:14], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7) #markersize 8\n",
    "            plt.plot(rands[14:] * 0.03 + offset - 0.36,\n",
    "                    diffs[14:], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7)\n",
    "            plt.errorbar(offset, this_var['diff'][0], color=color,\n",
    "                         yerr=this_var['std'][0], marker=marker,\n",
    "                        markersize=14, label='dummy')\n",
    "            if this_var['wilc'][0] < 0.05:\n",
    "                significance_str = '*'\n",
    "                if this_var['wilc'][0] < 0.01:\n",
    "                    significance_str = '**'\n",
    "                if this_var['wilc'][0] < 0.001:\n",
    "                    significance_str = '***'\n",
    "                plt.annotate(\n",
    "                        significance_str, xy = (offset, this_var['diff'][0]),\n",
    "                    xytext = (5, 15), fontsize=16,\n",
    "                        textcoords = 'offset points', ha = 'center', va = 'top',\n",
    "                color='black')\n",
    "            offset += 0.8\n",
    "        offset += 0.2\n",
    "    offset += 0.4\n",
    "#plt.ylim(-20,10)\n",
    "plt.axhline(y=0, color='grey', linestyle='dashed')\n",
    "\n",
    "plt.xticks(np.arange(1.,21,4), common_variants, rotation=23, fontsize=14)\n",
    "plt.grid('off', axis='x')\n",
    "#plt.xlim(-0.5, plt.xlim()[1]+0.5)\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "plt.xlim(-0.7,plt.xlim()[1]-1)\n",
    "plt.ylim(-80,50)\n",
    "\n",
    "# get handles\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "                 markersize=9, linewidth=0) for h in handles]\n",
    "# use them in the legend\n",
    "ax.legend(handles[:4], ('Deep 0-$f_{end}$ Hz', 'Shallow 0-$f_{end}$ Hz',\n",
    "                        'Deep 4-$f_{end}$ Hz','Shallow 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1,1),\n",
    "         fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "offset = 0\n",
    "for i_var, var_name in enumerate(uncommon_variants):\n",
    "    for freq in [\">0\", \">4\"]:\n",
    "        for net in 'shallow', 'deep5':\n",
    "            if net == 'shallow' and var_name in other_deep_vars:\n",
    "                continue\n",
    "            if net == 'deep5' and var_name in other_shallow_vars:\n",
    "                continue\n",
    "            markersize = 10\n",
    "            if net == 'deep5':\n",
    "                marker = 'o'\n",
    "            else:\n",
    "                assert net == 'shallow'\n",
    "                marker = '^'\n",
    "            if '>0' == freq:\n",
    "                color = seaborn.color_palette()[0]\n",
    "            elif '>4' == freq:\n",
    "                color = seaborn.color_palette()[1]\n",
    "            this_var = df_mod[(df_mod.variant == var_name) &\n",
    "                             (df_mod.net == net) & \n",
    "                             (df_mod.freq == freq) & \n",
    "                             (df_mod.dataset == 'combined')]\n",
    "            \n",
    "            baseline_test = this_var.test_baseline_subjects[0]\n",
    "            var_test = this_var.test_variant_subjects[0]\n",
    "            diffs = var_test - baseline_test\n",
    "            assert clean_mod_compare\n",
    "            plt.plot(rands[:14] * 0.05 + offset - 0.375,\n",
    "                    diffs[:14], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7) #markersize 8\n",
    "            plt.plot(rands[14:] * 0.05 + offset - 0.375,\n",
    "                    diffs[14:], color=color, marker=marker, alpha=0.55, linestyle='None',\n",
    "                    markersize=7)\n",
    "            plt.errorbar(offset, this_var['diff'][0], color=color,\n",
    "                         yerr=this_var['std'][0], marker=marker,\n",
    "                        markersize=14, label='dummy')\n",
    "            if this_var['wilc'][0] < 0.05:\n",
    "                significance_str = '*'\n",
    "                if this_var['wilc'][0] < 0.01:\n",
    "                    significance_str = '**'\n",
    "                if this_var['wilc'][0] < 0.001:\n",
    "                    significance_str = '***'\n",
    "                plt.annotate(\n",
    "                        significance_str, xy = (offset, this_var['diff'][0]),\n",
    "                    xytext = (5, 15), fontsize=16,\n",
    "                        textcoords = 'offset points', ha = 'center', va = 'top',)\n",
    "            offset += 0.6\n",
    "        offset += 0.2\n",
    "    offset += 0.5\n",
    "#plt.ylim(-20,10)\n",
    "plt.axhline(y=0, color='grey', linestyle='dashed')\n",
    "\n",
    "plt.xticks(np.arange(0.4,15,2.1), uncommon_variants, rotation=23,\n",
    "          fontsize=14)\n",
    "plt.grid('off', axis='x')\n",
    "plt.xlim(-0.7, plt.xlim()[1]+0.25)\n",
    "plt.ylabel('Accuracy Difference [%]', fontsize=14)\n",
    "plt.ylim(-40,30)\n",
    "# get handles\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# recreate  with empty line, only marker\n",
    "handles = [Line2D([0], [0], color=h[0].get_color(), marker=h[0].get_marker(),\n",
    "                 markersize=9, linewidth=0) for h in handles]\n",
    "# use them in the legend\n",
    "ax.legend(handles[:2] + handles[6:8], ('Shallow 0-$f_{end}$ Hz', 'Shallow 4-$f_{end}$ Hz',\n",
    "                                       'Deep 0-$f_{end}$ Hz','Deep 4-$f_{end}$ Hz'), \n",
    "          bbox_to_anchor=(1.,1),\n",
    "         fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_deep_epo_fft_bcic = load_data_frame('data/models/paper/bci-competition/epo/deep-fft/', shorten_headers=False)\n",
    "df_deep_epo_fft_ours = load_data_frame('data/models/paper/ours/epo/deep-fft/', shorten_headers=False)\n",
    "only_clean_sets = True\n",
    "if only_clean_sets:\n",
    "    df_deep_epo_fft_ours = clean_datasets(df_deep_epo_fft_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df_fft = pd.DataFrame()\n",
    "all_df_fft_comp = pd.DataFrame()\n",
    "\n",
    "dff = df_deep_epo_fft_bcic\n",
    "main_csp_bcic = restrict_or_unset(csp_above_0(df_csp_bcic), standardize=False,\n",
    "                                                                   standardize_cnt=False,\n",
    "                                 trial_start=500)\n",
    "\n",
    "dff = dff[(dff.num_filters_time == 25) & \n",
    "         (dff.preprocessor == 'null') &\n",
    "         (dff.filter_length_2 == 3) &\n",
    "         ((dff.layers == 'deep_fft_net_spat_time_freq')) &\n",
    "         (dff.frequency_end != 36) &\n",
    "         (dff.frequency_start != 4) &\n",
    "         (dff.include_phase == False) &\n",
    "         (dff.square_amplitude == False)]\n",
    "\n",
    "dff = above_0(dff)\n",
    "\n",
    "all_df_fft = pd.concat((all_df_fft, dff))\n",
    "\n",
    "for freq in ['0-40', '0-124']:\n",
    "    if freq == '0-40':\n",
    "        this_dfn = dff[dff.frequency_end == 40]\n",
    "        df_comp = compare_net_csp(this_dfn, main_csp_bcic,\n",
    "                                  'fft','0-40','bcic',)\n",
    "    else:\n",
    "        this_dfn = dff[dff.frequency_end == 'null']\n",
    "        assert freq == '0-124'\n",
    "        df_comp = compare_net_csp(this_dfn, main_csp_bcic,\n",
    "                                  'fft','0-124','bcic')\n",
    "    all_df_fft_comp = pd.concat((all_df_fft_comp, df_comp))\n",
    "\n",
    "\n",
    "        \n",
    "dataset_averaged_frame(remove_columns_with_same_value(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dff = df_deep_epo_fft_ours\n",
    "dff = dff[(dff.include_phase == False) & (dff.square_amplitude == False)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dff = df_deep_epo_fft_ours\n",
    "\n",
    "main_csp_ours = restrict_or_unset(clean_datasets(csp_above_0(df_csp_ours)), standardize=False,\n",
    "                                                                   standardize_cnt=False,\n",
    "                                 trial_start=500, max_abs_threshold=800)\n",
    "\n",
    "dff = dff[(dff.num_filters_time == 25) & \n",
    "         (dff.preprocessor == 'null') &\n",
    "         (dff.filter_length_2 == 3) &\n",
    "         ((dff.layers == 'deep_fft_net_spat_time_freq') | (dff.layers == 'seperated_linear')) &\n",
    "         (dff.include_phase == False) &\n",
    "         (dff.square_amplitude == False)]\n",
    "\n",
    "dff = above_0(dff)\n",
    "\n",
    "all_df_fft = pd.concat((all_df_fft, dff))\n",
    "\n",
    "for freq in ['0-40', '0-124']:\n",
    "    if freq == '0-40':\n",
    "        this_dfn = dff[dff.frequency_end == 40]\n",
    "        df_comp = compare_net_csp(this_dfn, main_csp_ours,\n",
    "                                  'fft','0-40','ours',)\n",
    "    else:\n",
    "        this_dfn = dff[dff.frequency_end == 'null']\n",
    "        assert freq == '0-124'\n",
    "        df_comp = compare_net_csp(this_dfn, main_csp_ours,\n",
    "                                  'fft','0-124','ours')\n",
    "    all_df_fft_comp = pd.concat((all_df_fft_comp, df_comp))\n",
    "    \n",
    "dataset_averaged_frame(remove_columns_with_same_value(dff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for freq in ['0-40', '0-124']:\n",
    "    if freq == '0-40':\n",
    "        this_dfn = all_df_fft[all_df_fft.frequency_end == 40]\n",
    "        df_comp = compare_net_csp(this_dfn, \n",
    "                                  csp_above_0(pd.concat((main_csp_ours, main_csp_bcic))),\n",
    "                                  'fft', '0-40', 'combined',)\n",
    "    else:\n",
    "        this_dfn = all_df_fft[all_df_fft.frequency_end == 'null']\n",
    "        assert freq == '0-124'\n",
    "        df_comp = compare_net_csp(this_dfn,\n",
    "                                  csp_above_0(pd.concat((main_csp_ours, main_csp_bcic))),\n",
    "                                  'fft', '0-124', 'combined')\n",
    "    all_df_fft_comp = pd.concat((all_df_fft_comp, df_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df_fft_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_columns_with_same_value(dff).iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.load import load_exp_and_model\n",
    "from braindecode.veganlasagne.layer_util import print_layers\n",
    "_, fft_model = load_exp_and_model('data/models/paper/ours/epo/deep-fft/40')\n",
    "\n",
    "print_layers(fft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "lasagne.layers.get_all_layers(fft_model)[3].pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp, model = load_exp_and_model('data/models/paper/ours/cnt/resnet/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.veganlasagne.layers import get_n_sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_resnet_bcic_old = load_data_frame('data/models/paper/before-trial-start-reruns/bci-competition/cnt/resnet/', params=dict(whisker_percent=None),\n",
    "                            shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_df = df_resnet_bcic_old.copy()\n",
    "old_df = the_df[(old_df.batch_modifier == 'null') & \n",
    "                (old_df.loss_expression == 'tied_neighbours_decay') &\n",
    "               (old_df.add_after_nonlin == '-') &\n",
    "               (old_df.split_first_layer == True)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(old_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = df_resnet_bcic[(df_resnet_bcic.low_cut_hz == 0) &\n",
    "                       (df_resnet_bcic.high_cut_hz == 38)]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.concat([new_df, old_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_row = new_df.iloc[0]\n",
    "old_row = old_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.setdiff1d(new_row.index, old_row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.setdiff1d(old_row.index, new_row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_indices = np.intersect1d(old_row.index, new_row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_resnet_bcic = load_data_frame('data/models/paper/bci-competition/cnt/resnet/', params=dict(whisker_percent=None),\n",
    "                            shorten_headers=False)\n",
    "assert np.all(df_resnet_bcic.max_abs_threshold == 800)\n",
    "assert np.all(df_resnet_bcic.trial_start == 1500)\n",
    "df_resnet_bcic = df_resnet_bcic[df_resnet_bcic.loss_expression == 'tied_neighbours_decay']\n",
    "averaged_frame = dataset_averaged_frame(remove_columns_with_same_value(df_resnet_bcic))\n",
    "averaged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_resnet_ours_old = load_data_frame('data/models/paper/before-trial-start-reruns/ours/cnt/resnet/', params=dict(whisker_percent=None),\n",
    "                            shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(clean_datasets(df_resnet_ours_old)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def no_bp_meaner(df):\n",
    "    return df[df.batch_modifier != 'bp_meaner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(above_0(df_resnet_bcic),\n",
    "                all_df[(all_df.dataset == 'bcic') & (all_df.clean ==True) &\n",
    "                       (all_df.net == 'deep5') & (all_df.train_type == 'cnt') &\n",
    "                             (all_df.max_abs_threshold == 800) &\n",
    "                             (all_df.trial_start == -500) &\n",
    "                             (all_df.freq == \">0\")], \n",
    "                'resnet','>0','bcic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_resnet = True\n",
    "df_resnet_ours = load_data_frame('data/models/paper/ours/cnt/resnet/', params=dict(whisker_percent=None),\n",
    "                            shorten_headers=False)\n",
    "df_resnet_ours = df_resnet_ours[df_resnet_ours.loss_expression == 'tied_neighbours_decay']\n",
    "assert np.all(df_resnet_ours.max_abs_threshold == 800)\n",
    "assert np.all(df_resnet_ours.trial_start == 1500)\n",
    "if clean_resnet:\n",
    "    df_resnet_ours = clean_datasets(df_resnet_ours)\n",
    "\n",
    "averaged_frame = dataset_averaged_frame(remove_columns_with_same_value(df_resnet_ours))\n",
    "averaged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_columns_with_same_value(df_resnet_ours[(df_resnet_ours.loss_expression == 'tied_neighbours_decay') & \n",
    "                                             (df_resnet_ours.low_cut_hz == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(above_0(df_resnet_ours),\n",
    "                all_df[(all_df.dataset == 'ours') & (all_df.clean ==True) &\n",
    "                       (all_df.net == 'deep5') & (all_df.train_type == 'cnt') &\n",
    "                             (all_df.max_abs_threshold == 800) &\n",
    "                             (all_df.trial_start == -500) &\n",
    "                             (all_df.freq == \">0\")],\n",
    "                'resnet','>0','ours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(pd.concat((above_0(df_resnet_bcic), above_0(df_resnet_ours))),\n",
    "                pd.concat((all_df[(all_df.dataset == 'bcic') & (all_df.clean ==True) &\n",
    "                       (all_df.net == 'deep5') & (all_df.train_type == 'cnt') &\n",
    "                             (all_df.max_abs_threshold == 800) &\n",
    "                             (all_df.trial_start == -500) &\n",
    "                             (all_df.freq == \">0\")],\n",
    "            all_df[(all_df.dataset == 'ours') & (all_df.clean ==True) &\n",
    "                       (all_df.net == 'deep5') & (all_df.train_type == 'cnt') &\n",
    "                             (all_df.max_abs_threshold == 800) &\n",
    "                             (all_df.trial_start == -500) &\n",
    "                             (all_df.freq == \">0\")])),\n",
    "                'resnet','>0','combined', max_n_p_vals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training TImes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_ours = load_data_frame('data/models/paper/ours/csp/', shorten_headers=False)\n",
    "df_csp_bcic = load_data_frame('data/models/paper/bci-competition/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html, display, HTML\n",
    "from braindecode.analysis.pandas_util import dataset_averaged_frame, remove_columns_with_same_value, load_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_bci_competition_times(folder):\n",
    "    display(HTML(\"<h5>Shallow</h5>\"))\n",
    "    display_html(dataset_averaged_frame(remove_columns_with_same_value(\n",
    "        clean_datasets(load_data_frame('data/models/paper/bci-competition/cnt/shallow/{:s}/'.format(folder),\n",
    "                                  shorten_headers=False)))))\n",
    "    display(HTML(\"<h5>Deep</h5>\"))\n",
    "    display_html(dataset_averaged_frame(remove_columns_with_same_value(\n",
    "        clean_datasets(load_data_frame('data/models/paper/bci-competition/cnt/deep4/{:s}/'.format(folder),\n",
    "                                  shorten_headers=False)))))\n",
    "    \n",
    "def display_ours_times(folder):\n",
    "    display(HTML(\"<h5>Shallow</h5>\"))\n",
    "    display_html(dataset_averaged_frame(remove_columns_with_same_value(\n",
    "        clean_datasets(load_data_frame('data/models/paper/ours-before-cz-0/cnt/shallow/{:s}/'.format(folder),\n",
    "                                  shorten_headers=False)))))\n",
    "    display(HTML(\"<h5>Deep</h5>\"))\n",
    "    display_html(dataset_averaged_frame(remove_columns_with_same_value(\n",
    "        clean_datasets(load_data_frame('data/models/paper/ours-before-cz-0/cnt/deep4/{:s}/'.format(folder),\n",
    "                                  shorten_headers=False)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCI Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(csp_above_0(df_csp_bcic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_bci_competition_times('traintime-rz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_bci_competition_times('traintime-tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(csp_above_0(df_csp_ours)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(all_df[(all_df.dataset =='ours') &\n",
    "                             (all_df.clean == False)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_ours_times('traintime-rz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_ours_times('traintime-tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(\n",
    "    clean_datasets(load_data_frame('data/models/paper/ours/cnt/shallow/traintime-rz/',\n",
    "                                  shorten_headers=False))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(\n",
    "    clean_datasets(load_data_frame('data/models/paper/ours/cnt/deep4/traintime-rz/',\n",
    "                                  shorten_headers=False))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old trianing times, unclear which queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfn = restrict(shallow_cnt_default(tied_loss(above_0(square_shallow(df_shallow_cnt_bcic)))), drop_p='-')\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfn = no_bp_meaner(tied_loss(deep_5_new_default(above_0(elu_deep_5(df_deep_cnt_bcic)))))\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfn = restrict(shallow_cnt_default(tied_loss(above_0(square_shallow(df_shallow_cnt_ours)))), drop_p='-', tag='repl')\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfn = no_bp_meaner(tied_loss(deep_5_new_default(above_0(elu_deep_5(df_deep_cnt_ours)))))\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New ours Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_columns_with_same_value(load_data_frame('data/models/paper/ours-before-cz-0/csp/car/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_deep_ours_new = load_data_frame('data/models/paper/ours/cnt/deep5/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgd = dataset_averaged_frame(remove_columns_with_same_value(df_deep_ours_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_shallow_ours_new = load_data_frame('data/models/paper/ours/cnt/shallow/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(df_shallow_ours_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strfdelta(tdelta, fmt):\n",
    "    \"\"\"For numpy timedelta, modified from\n",
    "    http://stackoverflow.com/a/8907269/1469195\"\"\"\n",
    "    d = {\"days\": tdelta.astype('timedelta64[D]').astype(np.int32)}\n",
    "    # only those seconds not absorbed by day\n",
    "    seconds = tdelta.astype('timedelta64[s]').astype(np.int32) % (3600 * 24)\n",
    "   \n",
    "    d[\"hours\"], rem = divmod(seconds, 3600)\n",
    "    d[\"minutes\"], d[\"seconds\"] = divmod(rem, 60)\n",
    "    return fmt.format(**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_lens = np.array(avgd['time', 'len'])\n",
    "time_means = np.array(avgd['time', 'tmean'])\n",
    "\n",
    "n_open_exps_per_variant = 20 - time_lens\n",
    "n_open_exps = np.sum(n_open_exps_per_variant)\n",
    "remaining_time_per_variant = n_open_exps_per_variant * time_means\n",
    "\n",
    "avg_time_per_exp = np.sum(time_means * time_lens) / float(np.sum(time_lens))\n",
    "total_time = n_open_exps * avg_time_per_exp\n",
    "print strfdelta(np.sum(remaining_time_per_variant) / 14.0, \"{days} days {hours}:{minutes}:{seconds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(load_data_frame('data/models/paper/ours/epo/shallow//')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(load_data_frame('data/models/paper/ours/epo/deep4/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(df_csp_ours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shallow_wanted = tied_loss(square_shallow(shallow_cnt_default(yes_drop(yes_bnorm(above_4(df_clean))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_shallow_wanted = remove_columns_with_same_value(df_shallow_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(df_shallow_wanted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_csp_wanted = remove_columns_with_same_value(csp_above_4(df_csp_ours_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(df_csp_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_net_csp(df_shallow_wanted, df_csp_wanted,'shallow', '4', 'ours',with_csp_acc=True,with_std=True,\n",
    "               with_std_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(df_csp_ours_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_clean = df_shallow_ours_new.copy()\n",
    "df_csp_ours_clean = df_csp_ours.copy\n",
    "for name in unclean_sets:\n",
    "    df_clean = df_clean[np.logical_not(df_clean.dataset_filename.str.contains(name))]\n",
    "    df_csp_ours_clean = df_csp_ours_clean[np.logical_not(df_csp_ours_clean.dataset_filename.str.contains(name))]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_clean))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_ours = load_data_frame('data/models/paper/ours/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(remove_columns_with_same_value(df_csp_ours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_csp = df_csp_ours.copy()\n",
    "for name in unclean_sets:\n",
    "    df_clean_csp = df_clean_csp[np.logical_not(df_clean_csp.dataset_filename.str.contains(name))]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(df_clean_csp))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ours = df_shallow_cnt_ours\n",
    "\n",
    "param_keys = df_ours.columns\n",
    "\n",
    "param_keys = set(param_keys) - set(['test', 'train', 'time', 'max_epochs', 'max_increasing_epochs'])\n",
    "\n",
    "df_long = df_ours[df_ours.max_increasing_epochs == 160]\n",
    "df_quick = df_ours[df_ours.max_increasing_epochs == 80]\n",
    "\n",
    "df_merged = df_long.merge(df_quick, on=list(param_keys), suffixes=('_long', '_quick'))\n",
    "\n",
    "plt.plot(df_merged.test_long - df_merged.test_quick)\n",
    "plt.axhline(y=0, color='k')\n",
    "print np.mean(df_merged.test_long - df_merged.test_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ours = df_deep_cnt_ours\n",
    "\n",
    "param_keys = df_ours.columns\n",
    "\n",
    "param_keys = set(param_keys) - set(['test', 'train', 'time', 'max_epochs', 'max_increasing_epochs'])\n",
    "\n",
    "df_long = df_ours[df_ours.max_increasing_epochs == 160]\n",
    "df_quick = df_ours[df_ours.max_increasing_epochs == 80]\n",
    "\n",
    "df_merged = df_long.merge(df_quick, on=list(param_keys), suffixes=('_long', '_quick'))\n",
    "\n",
    "plt.plot(df_merged.test_long - df_merged.test_quick)\n",
    "plt.axhline(y=0, color='k')\n",
    "print np.mean(df_merged.test_long - df_merged.test_quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vs different trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ours = df_shallow_cnt_ours\n",
    "\n",
    "param_keys = df_ours.columns\n",
    "\n",
    "param_keys = set(param_keys) - set(['test', 'train', 'time', 'max_epochs', 'max_increasing_epochs', 'trial_start'])\n",
    "\n",
    "df_long = df_ours[df_ours.trial_start == 2000]\n",
    "df_quick = df_ours[df_ours.max_increasing_epochs == 80]\n",
    "\n",
    "df_merged = df_long.merge(df_quick, on=list(param_keys), suffixes=('_long', '_quick'))\n",
    "\n",
    "plt.plot(df_merged.test_long - df_merged.test_quick)\n",
    "plt.axhline(y=0, color='k')\n",
    "print np.mean(df_merged.test_long - df_merged.test_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ours = df_deep_cnt_ours\n",
    "\n",
    "param_keys = df_ours.columns\n",
    "\n",
    "param_keys = set(param_keys) - set(['test', 'train', 'time', 'max_epochs', 'max_increasing_epochs', 'trial_start'])\n",
    "\n",
    "df_long = df_ours[df_ours.trial_start == 2000]\n",
    "df_quick = df_ours[df_ours.max_increasing_epochs == 80]\n",
    "\n",
    "df_merged = df_long.merge(df_quick, on=list(param_keys), suffixes=('_long', '_quick'))\n",
    "\n",
    "plt.plot(df_merged.test_long - df_merged.test_quick)\n",
    "plt.axhline(y=0, color='k')\n",
    "print np.mean(df_merged.test_long - df_merged.test_quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCI competition CSP with >0 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_bcic = load_data_frame('data/models/paper/bci-competition/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfc = df_csp_bcic\n",
    "dfc = dfc[dfc.min_freq == 1.0]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfc)).sort_values(('test', 'mean'),ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_csp_ours = load_data_frame('data/models/paper/ours/csp/', shorten_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfc = df_csp_ours\n",
    "dfc = dfc[dfc.min_freq == 1.0]\n",
    "dataset_averaged_frame(remove_columns_with_same_value(dfc)).sort_values(('test', 'mean'),ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ilya comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_filename</th>\n",
       "      <th>test</th>\n",
       "      <th>test_filename</th>\n",
       "      <th>test_sample</th>\n",
       "      <th>time</th>\n",
       "      <th>train</th>\n",
       "      <th>train_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>data/BBCI-without-last-runs/BhNoMoSc1S001R01_d...</td>\n",
       "      <td>94.375000</td>\n",
       "      <td>data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10...</td>\n",
       "      <td>89.865498</td>\n",
       "      <td>00:20:45</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.815654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>data/BBCI-without-last-runs/FaMaMoSc1S001R01_d...</td>\n",
       "      <td>86.163522</td>\n",
       "      <td>data/BBCI-only-last-runs/FaMaMoSc1S001R15_ds10...</td>\n",
       "      <td>82.553567</td>\n",
       "      <td>00:23:01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.081152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>data/BBCI-without-last-runs/FrThMoSc1S001R01_d...</td>\n",
       "      <td>89.375000</td>\n",
       "      <td>data/BBCI-only-last-runs/FrThMoSc1S001R12_ds10...</td>\n",
       "      <td>87.627141</td>\n",
       "      <td>00:38:14</td>\n",
       "      <td>98.967890</td>\n",
       "      <td>97.780092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>data/BBCI-without-last-runs/GuJoMoSc01S001R01_...</td>\n",
       "      <td>61.875000</td>\n",
       "      <td>data/BBCI-only-last-runs/GuJoMoSc01S001R12_ds1...</td>\n",
       "      <td>61.960653</td>\n",
       "      <td>00:25:36</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.687682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>data/BBCI-without-last-runs/KaUsMoSc1S001R01_d...</td>\n",
       "      <td>91.875000</td>\n",
       "      <td>data/BBCI-only-last-runs/KaUsMoSc1S001R12_ds10...</td>\n",
       "      <td>87.760974</td>\n",
       "      <td>00:37:16</td>\n",
       "      <td>99.886364</td>\n",
       "      <td>99.356993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>data/BBCI-without-last-runs/LaKaMoSc1S001R01_d...</td>\n",
       "      <td>93.125000</td>\n",
       "      <td>data/BBCI-only-last-runs/LaKaMoSc1S001R10_ds10...</td>\n",
       "      <td>89.314775</td>\n",
       "      <td>00:26:27</td>\n",
       "      <td>99.847095</td>\n",
       "      <td>99.661611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>data/BBCI-without-last-runs/LuFiMoSc3S001R01_d...</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>data/BBCI-only-last-runs/LuFiMoSc3S001R12_ds10...</td>\n",
       "      <td>79.553667</td>\n",
       "      <td>00:32:34</td>\n",
       "      <td>99.506782</td>\n",
       "      <td>96.590642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>data/BBCI-without-last-runs/MaJaMoSc1S001R01_d...</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaJaMoSc1S001R12_ds10...</td>\n",
       "      <td>83.053399</td>\n",
       "      <td>00:19:00</td>\n",
       "      <td>99.507995</td>\n",
       "      <td>97.620045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>data/BBCI-without-last-runs/MaKiMoSC01S001R01_...</td>\n",
       "      <td>90.625000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaKiMoSC01S001R05_ds1...</td>\n",
       "      <td>85.072270</td>\n",
       "      <td>00:07:21</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.942271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>data/BBCI-without-last-runs/MaVoMoSc1S001R01_d...</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaVoMoSc1S001R12_ds10...</td>\n",
       "      <td>94.771815</td>\n",
       "      <td>00:36:11</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.103562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>data/BBCI-without-last-runs/PiWiMoSc1S001R01_d...</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>data/BBCI-only-last-runs/PiWiMoSc1S001R12_ds10...</td>\n",
       "      <td>91.036536</td>\n",
       "      <td>00:31:56</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.585774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>data/BBCI-without-last-runs/RoBeMoSc03S001R01_...</td>\n",
       "      <td>98.125000</td>\n",
       "      <td>data/BBCI-only-last-runs/RoBeMoSc03S001R10_ds1...</td>\n",
       "      <td>96.981397</td>\n",
       "      <td>00:21:17</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.971707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>data/BBCI-without-last-runs/RoScMoSc1S001R01_d...</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>data/BBCI-only-last-runs/RoScMoSc1S001R12_ds10...</td>\n",
       "      <td>95.185359</td>\n",
       "      <td>00:24:19</td>\n",
       "      <td>99.545455</td>\n",
       "      <td>98.814605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>data/BBCI-without-last-runs/StHeMoSc01S001R01_...</td>\n",
       "      <td>84.276730</td>\n",
       "      <td>data/BBCI-only-last-runs/StHeMoSc01S001R11_ds1...</td>\n",
       "      <td>79.132156</td>\n",
       "      <td>00:28:19</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>98.627944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      dataset_filename       test  \\\n",
       "388  data/BBCI-without-last-runs/BhNoMoSc1S001R01_d...  94.375000   \n",
       "460  data/BBCI-without-last-runs/FaMaMoSc1S001R01_d...  86.163522   \n",
       "191  data/BBCI-without-last-runs/FrThMoSc1S001R01_d...  89.375000   \n",
       "231  data/BBCI-without-last-runs/GuJoMoSc01S001R01_...  61.875000   \n",
       "507  data/BBCI-without-last-runs/KaUsMoSc1S001R01_d...  91.875000   \n",
       "605  data/BBCI-without-last-runs/LaKaMoSc1S001R01_d...  93.125000   \n",
       "695  data/BBCI-without-last-runs/LuFiMoSc3S001R01_d...  85.000000   \n",
       "277  data/BBCI-without-last-runs/MaJaMoSc1S001R01_d...  86.250000   \n",
       "367  data/BBCI-without-last-runs/MaKiMoSC01S001R01_...  90.625000   \n",
       "489  data/BBCI-without-last-runs/MaVoMoSc1S001R01_d...  97.500000   \n",
       "376  data/BBCI-without-last-runs/PiWiMoSc1S001R01_d...  93.750000   \n",
       "437  data/BBCI-without-last-runs/RoBeMoSc03S001R01_...  98.125000   \n",
       "545  data/BBCI-without-last-runs/RoScMoSc1S001R01_d...  97.500000   \n",
       "580  data/BBCI-without-last-runs/StHeMoSc01S001R01_...  84.276730   \n",
       "\n",
       "                                         test_filename  test_sample     time  \\\n",
       "388  data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10...    89.865498 00:20:45   \n",
       "460  data/BBCI-only-last-runs/FaMaMoSc1S001R15_ds10...    82.553567 00:23:01   \n",
       "191  data/BBCI-only-last-runs/FrThMoSc1S001R12_ds10...    87.627141 00:38:14   \n",
       "231  data/BBCI-only-last-runs/GuJoMoSc01S001R12_ds1...    61.960653 00:25:36   \n",
       "507  data/BBCI-only-last-runs/KaUsMoSc1S001R12_ds10...    87.760974 00:37:16   \n",
       "605  data/BBCI-only-last-runs/LaKaMoSc1S001R10_ds10...    89.314775 00:26:27   \n",
       "695  data/BBCI-only-last-runs/LuFiMoSc3S001R12_ds10...    79.553667 00:32:34   \n",
       "277  data/BBCI-only-last-runs/MaJaMoSc1S001R12_ds10...    83.053399 00:19:00   \n",
       "367  data/BBCI-only-last-runs/MaKiMoSC01S001R05_ds1...    85.072270 00:07:21   \n",
       "489  data/BBCI-only-last-runs/MaVoMoSc1S001R12_ds10...    94.771815 00:36:11   \n",
       "376  data/BBCI-only-last-runs/PiWiMoSc1S001R12_ds10...    91.036536 00:31:56   \n",
       "437  data/BBCI-only-last-runs/RoBeMoSc03S001R10_ds1...    96.981397 00:21:17   \n",
       "545  data/BBCI-only-last-runs/RoScMoSc1S001R12_ds10...    95.185359 00:24:19   \n",
       "580  data/BBCI-only-last-runs/StHeMoSc01S001R11_ds1...    79.132156 00:28:19   \n",
       "\n",
       "          train  train_sample  \n",
       "388  100.000000     99.815654  \n",
       "460  100.000000     99.081152  \n",
       "191   98.967890     97.780092  \n",
       "231  100.000000     99.687682  \n",
       "507   99.886364     99.356993  \n",
       "605   99.847095     99.661611  \n",
       "695   99.506782     96.590642  \n",
       "277   99.507995     97.620045  \n",
       "367  100.000000     99.942271  \n",
       "489  100.000000     99.103562  \n",
       "376  100.000000     99.585774  \n",
       "437  100.000000     99.971707  \n",
       "545   99.545455     98.814605  \n",
       "580  100.000000     98.627944  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilya_df = all_df.copy()\n",
    "ilya_df = ilya_df[(ilya_df.net == 'shallow') &\n",
    "                 (ilya_df.max_abs_threshold == 800) &\n",
    "                 (ilya_df.freq == '>0') & \n",
    "                 (ilya_df.clean == True) &\n",
    "                 (ilya_df.dataset == 'ours') &\n",
    "                 (ilya_df.train_type == 'cnt')]\n",
    "ilya_df = ilya_df.drop('layer_names_to_norms', axis=1)\n",
    "reduced_ilya_df = remove_columns_with_same_value(ilya_df).sort_values(by='dataset_filename')\n",
    "reduced_ilya_df.to_csv('shallow.csv')\n",
    "reduced_ilya_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.99065772474799"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced_ilya_df.test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.83911961858053"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced_ilya_df[~reduced_ilya_df.dataset_filename.str.contains('GuJo')].test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_filename</th>\n",
       "      <th>test</th>\n",
       "      <th>test_filename</th>\n",
       "      <th>test_sample</th>\n",
       "      <th>time</th>\n",
       "      <th>train</th>\n",
       "      <th>train_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>data/BBCI-without-last-runs/BhNoMoSc1S001R01_d...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10...</td>\n",
       "      <td>98.530141</td>\n",
       "      <td>00:39:49</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.943668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>data/BBCI-without-last-runs/FaMaMoSc1S001R01_d...</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>data/BBCI-only-last-runs/FaMaMoSc1S001R15_ds10...</td>\n",
       "      <td>89.956146</td>\n",
       "      <td>00:49:02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.391947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>data/BBCI-without-last-runs/FrThMoSc1S001R01_d...</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>data/BBCI-only-last-runs/FrThMoSc1S001R12_ds10...</td>\n",
       "      <td>87.798800</td>\n",
       "      <td>01:37:29</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.403861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>data/BBCI-without-last-runs/GuJoMoSc01S001R01_...</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>data/BBCI-only-last-runs/GuJoMoSc01S001R12_ds1...</td>\n",
       "      <td>63.436195</td>\n",
       "      <td>00:46:39</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.977344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>data/BBCI-without-last-runs/KaUsMoSc1S001R01_d...</td>\n",
       "      <td>94.375000</td>\n",
       "      <td>data/BBCI-only-last-runs/KaUsMoSc1S001R12_ds10...</td>\n",
       "      <td>91.443763</td>\n",
       "      <td>00:49:27</td>\n",
       "      <td>99.886364</td>\n",
       "      <td>99.317114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>data/BBCI-without-last-runs/LaKaMoSc1S001R01_d...</td>\n",
       "      <td>93.125000</td>\n",
       "      <td>data/BBCI-only-last-runs/LaKaMoSc1S001R10_ds10...</td>\n",
       "      <td>90.645877</td>\n",
       "      <td>00:48:38</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.764417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>data/BBCI-without-last-runs/LuFiMoSc3S001R01_d...</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>data/BBCI-only-last-runs/LuFiMoSc3S001R12_ds10...</td>\n",
       "      <td>83.985517</td>\n",
       "      <td>00:50:32</td>\n",
       "      <td>99.260173</td>\n",
       "      <td>96.089135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>data/BBCI-without-last-runs/MaJaMoSc1S001R01_d...</td>\n",
       "      <td>89.375000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaJaMoSc1S001R12_ds10...</td>\n",
       "      <td>85.117432</td>\n",
       "      <td>00:39:30</td>\n",
       "      <td>99.753998</td>\n",
       "      <td>98.267840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>data/BBCI-without-last-runs/MaKiMoSC01S001R01_...</td>\n",
       "      <td>94.375000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaKiMoSC01S001R05_ds1...</td>\n",
       "      <td>92.088987</td>\n",
       "      <td>00:11:55</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.754910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>data/BBCI-without-last-runs/MaVoMoSc1S001R01_d...</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>data/BBCI-only-last-runs/MaVoMoSc1S001R12_ds10...</td>\n",
       "      <td>97.173800</td>\n",
       "      <td>01:09:39</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.867266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>data/BBCI-without-last-runs/PiWiMoSc1S001R01_d...</td>\n",
       "      <td>96.875000</td>\n",
       "      <td>data/BBCI-only-last-runs/PiWiMoSc1S001R12_ds10...</td>\n",
       "      <td>94.455245</td>\n",
       "      <td>01:03:54</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.946201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>data/BBCI-without-last-runs/RoBeMoSc03S001R01_...</td>\n",
       "      <td>98.125000</td>\n",
       "      <td>data/BBCI-only-last-runs/RoBeMoSc03S001R10_ds1...</td>\n",
       "      <td>97.295799</td>\n",
       "      <td>00:27:06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.975755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>data/BBCI-without-last-runs/RoScMoSc1S001R01_d...</td>\n",
       "      <td>96.250000</td>\n",
       "      <td>data/BBCI-only-last-runs/RoScMoSc1S001R12_ds10...</td>\n",
       "      <td>94.971294</td>\n",
       "      <td>00:47:41</td>\n",
       "      <td>99.772727</td>\n",
       "      <td>99.685306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>data/BBCI-without-last-runs/StHeMoSc01S001R01_...</td>\n",
       "      <td>91.823899</td>\n",
       "      <td>data/BBCI-only-last-runs/StHeMoSc01S001R11_ds1...</td>\n",
       "      <td>87.918357</td>\n",
       "      <td>01:11:14</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.727818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      dataset_filename        test  \\\n",
       "243  data/BBCI-without-last-runs/BhNoMoSc1S001R01_d...  100.000000   \n",
       "312  data/BBCI-without-last-runs/FaMaMoSc1S001R01_d...   94.339623   \n",
       "398  data/BBCI-without-last-runs/FrThMoSc1S001R01_d...   92.500000   \n",
       "252  data/BBCI-without-last-runs/GuJoMoSc01S001R01_...   62.500000   \n",
       "550  data/BBCI-without-last-runs/KaUsMoSc1S001R01_d...   94.375000   \n",
       "445  data/BBCI-without-last-runs/LaKaMoSc1S001R01_d...   93.125000   \n",
       "652  data/BBCI-without-last-runs/LuFiMoSc3S001R01_d...   91.250000   \n",
       "433  data/BBCI-without-last-runs/MaJaMoSc1S001R01_d...   89.375000   \n",
       "396  data/BBCI-without-last-runs/MaKiMoSC01S001R01_...   94.375000   \n",
       "617  data/BBCI-without-last-runs/MaVoMoSc1S001R01_d...   98.750000   \n",
       "611  data/BBCI-without-last-runs/PiWiMoSc1S001R01_d...   96.875000   \n",
       "810  data/BBCI-without-last-runs/RoBeMoSc03S001R01_...   98.125000   \n",
       "669  data/BBCI-without-last-runs/RoScMoSc1S001R01_d...   96.250000   \n",
       "541  data/BBCI-without-last-runs/StHeMoSc01S001R01_...   91.823899   \n",
       "\n",
       "                                         test_filename  test_sample     time  \\\n",
       "243  data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10...    98.530141 00:39:49   \n",
       "312  data/BBCI-only-last-runs/FaMaMoSc1S001R15_ds10...    89.956146 00:49:02   \n",
       "398  data/BBCI-only-last-runs/FrThMoSc1S001R12_ds10...    87.798800 01:37:29   \n",
       "252  data/BBCI-only-last-runs/GuJoMoSc01S001R12_ds1...    63.436195 00:46:39   \n",
       "550  data/BBCI-only-last-runs/KaUsMoSc1S001R12_ds10...    91.443763 00:49:27   \n",
       "445  data/BBCI-only-last-runs/LaKaMoSc1S001R10_ds10...    90.645877 00:48:38   \n",
       "652  data/BBCI-only-last-runs/LuFiMoSc3S001R12_ds10...    83.985517 00:50:32   \n",
       "433  data/BBCI-only-last-runs/MaJaMoSc1S001R12_ds10...    85.117432 00:39:30   \n",
       "396  data/BBCI-only-last-runs/MaKiMoSC01S001R05_ds1...    92.088987 00:11:55   \n",
       "617  data/BBCI-only-last-runs/MaVoMoSc1S001R12_ds10...    97.173800 01:09:39   \n",
       "611  data/BBCI-only-last-runs/PiWiMoSc1S001R12_ds10...    94.455245 01:03:54   \n",
       "810  data/BBCI-only-last-runs/RoBeMoSc03S001R10_ds1...    97.295799 00:27:06   \n",
       "669  data/BBCI-only-last-runs/RoScMoSc1S001R12_ds10...    94.971294 00:47:41   \n",
       "541  data/BBCI-only-last-runs/StHeMoSc01S001R11_ds1...    87.918357 01:11:14   \n",
       "\n",
       "          train  train_sample  \n",
       "243  100.000000     99.943668  \n",
       "312  100.000000     99.391947  \n",
       "398  100.000000     99.403861  \n",
       "252  100.000000     99.977344  \n",
       "550   99.886364     99.317114  \n",
       "445  100.000000     99.764417  \n",
       "652   99.260173     96.089135  \n",
       "433   99.753998     98.267840  \n",
       "396  100.000000     99.754910  \n",
       "617  100.000000     99.867266  \n",
       "611  100.000000     99.946201  \n",
       "810  100.000000     99.975755  \n",
       "669   99.772727     99.685306  \n",
       "541  100.000000     99.727818  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilya_df = all_df.copy()\n",
    "ilya_df = ilya_df[(ilya_df.net == 'deep5') &\n",
    "                 (ilya_df.max_abs_threshold == 800) &\n",
    "                 (ilya_df.freq == '>0') & \n",
    "                 (ilya_df.clean == True) &\n",
    "                 (ilya_df.dataset == 'ours') &\n",
    "                 (ilya_df.train_type == 'cnt')]\n",
    "ilya_df = ilya_df.drop('layer_names_to_norms', axis=1)\n",
    "reduced_ilya_df = remove_columns_with_same_value(ilya_df).sort_values(by='dataset_filename')\n",
    "reduced_ilya_df.to_csv('deep.csv')\n",
    "reduced_ilya_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.6298108846485"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced_ilya_df.test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.64470439898069"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced_ilya_df[~reduced_ilya_df.dataset_filename.str.contains('GuJo')].test_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
