{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCI Competition 4 Dataset 2a Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I show the evolution of the 5-layer performance across changing:\n",
    "* number of filters\n",
    "* filter lengths\n",
    "* avg pooling in final layer instead of fully connected\n",
    "* dropout on input\n",
    "* tied losses for samples of same trial\n",
    "* squared activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original values for the samplewise trained model were:\n",
    "\n",
    "|Highpass|Test|\n",
    "|-|\n",
    "|-|65.6%|\n",
    "|4|61.7%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Doubling after pooling increases ~3% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, we had 40 units per layer, we tried:\n",
    "  * 20,40,80,160\n",
    "  * 25,50,100,200\n",
    "  * 32,48,72,108\n",
    "  * 32,64,128,256\n",
    "  \n",
    "\n",
    "|#Units|Highpass|Test|\n",
    "|-|\n",
    "|20,40,80,160|-|68.1%|\n",
    "|20,40,80,160|4|63.1%|\n",
    "|25,50,100,200|-|69.5%|\n",
    "|25,50,100,200|4|64.0%|\n",
    "|32,48,72,108|-|63.9%|\n",
    "|32,48,72,108|-|63.8%|\n",
    "|32,64,128,256|-|68.6%|\n",
    "|32,64,128,256|-|65.9%|\n",
    "\n",
    "I continued with 25,50,100,200 since its faster and close to 32,64,128,256. Also I made a mistake (evaluating an experiment which had not finished on all datasets) which led me to believe the 32,64,128,256 is less robust... so 32,64,128,256 might actually be better...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made some smaller experiments with different filter lengths (15,7,3,3 compared to 10,10,10,10) in later layers which all had significantly worse results (< 60%). Might have to try more variants for a fairer comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AvgPool + Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average pool helps a little on highpassed data\n",
    "* same for dropout\n",
    "\n",
    "Using 25,50,100,200, we got:\n",
    "\n",
    "|Highpass|Dropout in|Test|\n",
    "|-|\n",
    "|-|-|67.6%|\n",
    "|4|-|65.1%|\n",
    "|-|0.1|67.5%|\n",
    "|4|0.1|66.4%|\n",
    "|-|0.3|68.1%|\n",
    "|4|0.3|66.0%|\n",
    "\n",
    "I resumed with dropout 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REDO AS YOU DID NOT SET FIRS TPOOL MODE TO MEAN(!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not help much. Note that factorization of for example 11x1 into 6x1+6x1 increases the number of weights (in contrast with 2d-filters where 11x11 has more parameters than 6x6+6x6).\n",
    "\n",
    "|Highpass|nonlin between|Test|\n",
    "|-|\n",
    "|-|-|70.7%|\n",
    "|4|-|65.9%|\n",
    "|-|elu|68.0%|\n",
    "|4|elu|63.3%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tied Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested either using 1,10 or 100 randomly chosen pairs (chosen so that any sample maximally appears once)or using all neighbouring samples.\n",
    "\n",
    "\n",
    "|Highpass|Tied pairs|Drop in prob|Test|\n",
    "|-|\n",
    "|-|1|0.0|65.8%|\n",
    "|-|10|0.0|68.0%|\n",
    "|-|100|0.0|67.8%|\n",
    "|-|neighb|0.0|69.7%|\n",
    "|4|1|0.0|62.5%|\n",
    "|4|10|0.0|66.7%|\n",
    "|4|100|0.0|67.4%|\n",
    "|4|neighb|0.0|67.7%|\n",
    "|-|1|0.1|64.2%|\n",
    "|-|10|0.1|66.8%|\n",
    "|-|100|0.1|67.2%|\n",
    "|-|neighb|0.1|70.2%|\n",
    "|4|1|0.1|60.7%|\n",
    "|4|10|0.1|64.3%|\n",
    "|4|100|0.1|65.7%|\n",
    "|4|neighb|0.1|65.7%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing avg pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Highpass|Tied pairs|Drop in prob|Test|\n",
    "|-|\n",
    "|-|neighb|0.0|71.0%|\n",
    "|4|neighb|0.0|67.2%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are test accuracy from 5-fold cross validation (in percent, mean over all 9 subjects). I show both blockwise cross validation, i.e., the test fold is one \"timeblock\" with all trials of a certain timeperiod, as well as shuffled cross validation, where the test fold can consist of any randomly selected trials from the data (but still has no trials in common with the train fold). I also show train-test split as in the competition, that means about 40% less training trials. We predict trialwise, so we do not do any continous samplewise prediction (I assume they did the same in their paper).\n",
    "\n",
    "\n",
    "The train folds have sizes $\\frac{4}{5} \\cdot 576 \\approx 461$, test folds $\\frac{1}{5} \\cdot 576 \\approx 115$.\n",
    "For train test split, train and test both have 288 trials.\n",
    "\n",
    "I report for three different forward/causal highpass filters, explanation below.\n",
    "\n",
    "|Method|Highpass (Hz)|Sampling Rate (Hz)|Blockwise (%)|Shuffled (%)|Train-Test-Split|Windowed Training**|***Windowed Model|\n",
    "|-|-|-|\n",
    "|CSP+CNN =>SFM (theirs)||250||69.27|||\n",
    "| FBCSP (theirs, 0.5-2.5s)||250|||67.01||\n",
    "| FBCSP (ours, 0.5-2.5s)||250|72.59|73.59|62.77||\n",
    "| FBCSP (ours, 0.5-2.5s), w/ fsel*||250|||64.20||\n",
    "| FBCSP (ours, 0.5-4s)||250|76.64|77.72|65.47||\n",
    "| FBCSP (ours, 0.5-4s), w/ fsel*||250|||67.17||\n",
    "|Raw Net (0-4s)|0.5 |150|76.19|77.78|69.25||\n",
    "|Raw Net (0-4s)|2.0 |150|71.78|72.68|66.17||\n",
    "|Raw Net (0-4s)|4.0 |150|69.89|71.18|64.54|63.43|64.66|\n",
    "|Raw Net No Drop**** (0-4s)|0.5 |150|||74.07||\n",
    "|Raw Net No Drop**** (0-4s)|2.0 |150|||73.46||\n",
    "|Raw Net No Drop**** (0-4s)|4.0 |150|||73.38|||\n",
    "|Raw Net (0-4s)|0.5 |250|76.75|77.66|69.33||\n",
    "|Raw Net (0-4s)|2.0 |250|71.07|72.45|65.59||\n",
    "|Raw Net (0-4s)|4.0 |250|70.28|70.77|64.81|62.85|66.09|\n",
    "|Raw Net No Drop**** (0-4s)|0.5 |250|||73.69||\n",
    "|Raw Net No Drop**** (0-4s)|2.0 |250|||74.34||\n",
    "|Raw Net No Drop**** (0-4s)|4.0 |250|||70.06|||\n",
    "|FB Net (0.5-4s)|0.5 |150|74.04|75.79|59.57||\n",
    "|FB Net (0.5-4s)|2.0 |150|73.90|75.48|59.68||\n",
    "|FB Net (0.5-4s)|4.0 |150|72.30|74.36|57.79|66.44|\n",
    "|FB Net (0.5-4s)|0.5 |250|72.41|74.81|61.00||\n",
    "|FB Net (0.5-4s)|2.0 |250|71.70|73.07|60.34||\n",
    "|FB Net (0.5-4s)|4.0 |250|71.35|72.34|57.99|67.21|\n",
    "\n",
    "* *w/ fsel means with feature selection\n",
    "* ** Windowed Training means I cut out windows of 2s from the 4s trials, shifting them through the trials with 100ms stride. It also was evaluated with the train test splits (using the sum over all windows predictions per trial)\n",
    "* *** Windowed model means the final fully connected layer is replaced by a convolutional layer + averaging over all convolution outputs. This translates to making a prediction over a time region, in our case of roughly 2 seconds. \n",
    "* **** Raw Net No Drop means no dropout between the first and second convolutional layer (time convolution and spatial convolution, they have no/identity activation between them). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Notes:\n",
    "\n",
    "* Results with *~* are estimations based on finished datasets. FB Net with 150 Hz shuffled should be finished by tuesday, with 250 Hz finished until end of week.\n",
    "* They use 500-2500ms, we use 0-4000ms. There was no constraint from the original dataset description. In the competition you originally had to predict samplewise, not trialwise, e.g. by shifting a window over all samples. Only constraint was to only use data from the past up to the current sample to predict the current sample. I could rerun with their timewindow if wanted. I originally ran with >0.5 Hz and their timewindow and 150 Hz and had 74.08% for raw net and 73.86% for fb net.\n",
    "* FBCSP our implementation also uses same 9 filterbands 4-8,8-12,...,36-40\n",
    "* FB Net with higher highpass, also has less frequency bands, removing band from 0.5-1Hz and from 1-3Hz respectively.\n",
    "* EOG artifacts need to be filtered out, maybe we use them? Quote from dataset description for competition:\n",
    "> Since three EOG channels are provided, it is required to remove EOG artifacts before the subsequent data processing using artifact removal techniques such as highpass filtering or linear regression.  In order to enable the application of other correction methods, we have opted for a maximum transparency approach and provided the EOG channels; at the same time we request that artifacts do not influence the classication result.\n",
    "\n",
    "     * At the moment I do not reject any trials or channels. This is the easiest setup as I do not have to change anything for running it on the unclean test set. I also assume they do not do any cleaning and that they believe their frequency bands (between 4 and 40 Hz) are relatively artifact free. So probably only our results above 4 Hz are comparable.\n",
    "* We do not know if they shuffled or didn't shuffle for their cross validation.\n",
    "* I do the highpass before even for the fb net, where it does not make much sense (since there is a bandpass after). This is just a legacy from the master thesis idea that every net should have as identical an input as possible. I can rerun fb net without highpass before, although that should not make a big difference (I think?), only that maybe minimally less relevant samples are shifted out of the time window by only doing forward filtering once.\n",
    "* Nets are identical to master thesis except for weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison values for train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All subjects for fb net/raw net 250 Hz train/test compared to FBCSP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see http://www.eurasip.org/Proceedings/Eusipco/Eusipco2015/papers/1570104275.pdf (other paper with results, see http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7318929)\n",
    "\n",
    "|Subject|FBCSP|CNN with MLP|\n",
    "|-|\n",
    "| S1 |79.16|80.55|\n",
    "| S2 |52.08|53.82|\n",
    "| S2 |83.33|84.72|\n",
    "| S4 |62.15|64.58|\n",
    "| S5 |54.51|59.03|\n",
    "| S6 |39.24|44.1|\n",
    "| S7 |83.33|84.03|\n",
    "| S8 |82.64|86.8|\n",
    "| S9 |66.67|77.77|\n",
    "|Avg |67.01|70.60|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
